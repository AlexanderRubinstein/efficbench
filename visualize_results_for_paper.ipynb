{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# import pickle\n",
    "from plots import (\n",
    "    MAX_TABLE_SIZE,\n",
    "    make_table_avg,\n",
    "    make_perf_table,\n",
    ")\n",
    "from utils import load_pickle\n",
    "from generating_data.utils_for_notebooks import merge_methods\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "\n",
    "FIGURES_FOLDER = './tmp/NeurIPS_2025_Accelerated-Model-Evaluation-by-Using-Similarities-in-Prediction-Space/figures'\n",
    "N_SAMPLES_FIGURE_FOLDER = os.path.join(FIGURES_FOLDER, 'num_samples')\n",
    "os.makedirs(FIGURES_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mae(mae_value):\n",
    "    if mae_value is None or mae_value == float('nan'):\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return round(mae_value * 100, 2)\n",
    "\n",
    "def prepare_rank(rank_value):\n",
    "    if rank_value is None or rank_value == float('nan'):\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return round(rank_value, 3)\n",
    "\n",
    "def make_table_1(data_for_table_1):\n",
    "\n",
    "    assert len(data_for_table_1) == 4 # mae and rank for mmlu and hellaswag\n",
    "\n",
    "    rows = []\n",
    "    mmlu_maes, num_anchors_mmlu_maes = data_for_table_1[0]\n",
    "    mmlu_ranks, num_anchors_mmlu_ranks = data_for_table_1[1]\n",
    "    hellaswag_maes, num_anchors_hellaswag_maes = data_for_table_1[2]\n",
    "    hellaswag_ranks, num_anchors_hellaswag_ranks = data_for_table_1[3]\n",
    "    assert num_anchors_mmlu_maes == num_anchors_mmlu_ranks == num_anchors_hellaswag_maes == num_anchors_hellaswag_ranks\n",
    "    num_anchors = num_anchors_mmlu_maes\n",
    "\n",
    "    if hellaswag_maes is None:\n",
    "        hellaswag_maes = mmlu_maes.copy()\n",
    "        hellaswag_maes.loc[:,:] = float('nan')\n",
    "    if hellaswag_ranks is None:\n",
    "        hellaswag_ranks = mmlu_ranks.copy()\n",
    "        hellaswag_ranks.loc[:,:] = float('nan')\n",
    "\n",
    "    rows.append([ # headers\n",
    "        \"Approach\",\n",
    "        \"Condensation\", # type\n",
    "        \"Condensation\", # num_anchors\n",
    "        \"Prediction\", # type\n",
    "        \"MMLU\", # mae\n",
    "        \"MMLU\", # rank\n",
    "        \"hellaswag\", # mae\n",
    "        \"hellaswag\", # rank\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"\",\n",
    "        \"type\", # type\n",
    "        \"num_anchors\", # num_anchors\n",
    "        \"type\", # type\n",
    "        \"mae\", # mae\n",
    "        \"rank\", # rank\n",
    "        \"mae\", # mae\n",
    "        \"rank\", # rank\n",
    "    ])\n",
    "    rows.append([ # RANDOM direct eval\n",
    "        \"Baseline\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"Eval\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"naive\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"naive\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"random\"][\"naive\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"random\"][\"naive\"]),\n",
    "    ])\n",
    "    # tinyBenchmarks\n",
    "    rows.append([ # Random gp-IRT\n",
    "        \"tinyBenchmarks\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"gp-IRT\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"gpirt\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"gpirt\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"random\"][\"gpirt\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"random\"][\"gpirt\"]),\n",
    "    ])\n",
    "    rows.append([ # anchor-IRT gp-IRT\n",
    "        \"tinyBenchmarks\",\n",
    "        \"anchor-IRT\",\n",
    "        num_anchors,\n",
    "        \"gp-IRT\",\n",
    "        prepare_mae(mmlu_maes.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "    ])\n",
    "    rows.append([ # anchor-correctness gp-IRT\n",
    "        \"tinyBenchmarks\",\n",
    "        \"anchor-correctness\",\n",
    "        num_anchors,\n",
    "        \"gp-IRT\",\n",
    "        prepare_mae(mmlu_maes.loc[\"anchor\"][\"gpirt\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"anchor\"][\"gpirt\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"anchor\"][\"gpirt\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"anchor\"][\"gpirt\"]),\n",
    "    ])\n",
    "    rows.append([ # Random KNN\n",
    "        \"Baseline\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"kNN\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"KNN\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"KNN\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"random\"][\"KNN\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"random\"][\"KNN\"]),\n",
    "    ])\n",
    "    rows.append([ # Random fit\n",
    "        \"Baseline\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"fit\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"fit\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"fit\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"random\"][\"fit\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"random\"][\"fit\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"DISCO (ours)\",\n",
    "        \"High PDS\",\n",
    "        num_anchors,\n",
    "        \"kNN\",\n",
    "        prepare_mae(mmlu_maes.loc[\"highest\"][\"KNN\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"highest\"][\"KNN\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"highest\"][\"KNN\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"highest\"][\"KNN\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"DISCO (ours)\",\n",
    "        \"High PDS\",\n",
    "        num_anchors,\n",
    "        \"fit\",\n",
    "        prepare_mae(mmlu_maes.loc[\"highest\"][\"fit\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"highest\"][\"fit\"]),\n",
    "        prepare_mae(hellaswag_maes.loc[\"highest\"][\"fit\"]),\n",
    "        prepare_rank(hellaswag_ranks.loc[\"highest\"][\"fit\"]),\n",
    "    ])\n",
    "\n",
    "    # res[\"baseline\"] = {\n",
    "    #     \"mae\": 0.0,\n",
    "    #     \"rank\": 0.0\n",
    "    # }\n",
    "    # res[\"ours\"] = {\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # display(df)\n",
    "\n",
    "    latex_str = make_table_1_latex(df)\n",
    "\n",
    "    return df, latex_str\n",
    "\n",
    "\n",
    "def make_table_1_latex(df):\n",
    "        # Add column headers\n",
    "    df.columns = [\"Approach\", \"Type\", \"# Samples\", \"Type\", \"MAE\", \"Rank\", \"MAE\", \"Rank\"]\n",
    "\n",
    "    # Create LaTeX table content\n",
    "    latex_str = \"\\\\begin{table}[H]\\n\"\n",
    "    latex_str += \"\\\\centering\\n\\\\small\\n\"\n",
    "    latex_str += \"\\\\begin{tabular}{c|cc|c|cc|cc}\\n\"\n",
    "    latex_str += \"\\\\toprule\\n\"\n",
    "    latex_str += \"\\\\multicolumn{1}{c}{\\\\textbf{Approach}}&\\\\multicolumn{2}{c}{\\\\textbf{Condensation}} & \\\\multicolumn{1}{c}{\\\\textbf{Prediction}} & \\\\multicolumn{2}{c}{\\\\textbf{MMLU}}& \\\\multicolumn{2}{c}{\\\\textbf{hellaswag}} \\\\\\\\\\n\"\n",
    "    latex_str += \"&Type & \\\\# \\\\negthinspace Samples & Type & {MAE}  &Rank& {MAE}  &Rank \\\\\\\\\\n\"\n",
    "    latex_str += \"\\\\toprule\\n\"\n",
    "\n",
    "    # Process each row\n",
    "    current_approach = \"\"\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"Approach\"] == \"Approach\" or row[\"Approach\"] == \"\":\n",
    "            continue\n",
    "        if row[\"Approach\"] == current_approach:\n",
    "            approach_str = \"\"\n",
    "        else:\n",
    "            approach_str = row[\"Approach\"]\n",
    "            current_approach = row[\"Approach\"]\n",
    "\n",
    "            # Add midrule before new approach except for first one\n",
    "            if approach_str != \"Baseline\":\n",
    "                latex_str += \"\\\\midrule\\n\"\n",
    "\n",
    "        # Format numbers\n",
    "        mae_mmlu = \"-\" if pd.isna(row[\"MAE\"].values[0]) else f\"{float(row['MAE'].values[0]):.2f}\"\n",
    "        rank_mmlu = \"-\" if pd.isna(row[\"Rank\"].values[0]) else f\"{float(row['Rank'].values[0]):.3f}\"\n",
    "        mae_hellaswag = \"-\" if pd.isna(row[\"MAE\"].values[1]) else f\"{float(row['MAE'].values[1]):.2f}\"\n",
    "        rank_hellaswag = \"-\" if pd.isna(row[\"Rank\"].values[1]) else f\"{float(row['Rank'].values[1]):.3f}\"\n",
    "\n",
    "        # Bold best results\n",
    "        if approach_str == \"DISCO (ours)\" and row[\"Type\"].values[1] == \"linear\":\n",
    "            mae_mmlu = f\"\\\\textbf{{{mae_mmlu}}}\"\n",
    "            rank_mmlu = f\"\\\\textbf{{{rank_mmlu}}}\"\n",
    "\n",
    "        latex_str += f\"{approach_str}&{row['Type'].values[0]} & {row['# Samples']} & {row['Type'].values[1]} & {mae_mmlu} &{rank_mmlu} & {mae_hellaswag} &{rank_hellaswag} \\\\\\\\\\n\"\n",
    "\n",
    "    latex_str += \"\\\\bottomrule\\n\"\n",
    "    latex_str += \"\\\\end{tabular}\\n\"\n",
    "    latex_str += \"\\\\vspace{1em}\\n\"\n",
    "    latex_str += \"\\\\caption{Mean Absolute Error (MAE) for different sampling and prediction strategies. For question answering task on MMLU dataset [FIX]. \\\\joon{Add computational complexity info\\nAdd hellaswag results, add ranking metric, add method from hellaswag.\\n}}\\n\"\n",
    "    latex_str += \"\\\\label{tab:language-main}\\n\"\n",
    "    latex_str += \"\\\\end{table}\"\n",
    "\n",
    "    # Store LaTeX code in DataFrame metadata\n",
    "    df.attrs['latex_table'] = latex_str\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "def extract_data_for_table_1(source_df, num_anchors, lower_better, key=\"PDS type\"):\n",
    "    # Group by PDS type and calculate mean for each group\n",
    "    df = source_df[num_anchors]\n",
    "    # For debugging:\n",
    "    # display(df)\n",
    "    # if num_anchors == 100 and not lower_better:\n",
    "    #     display(df)\n",
    "    # print(\"DEBUG\")\n",
    "\n",
    "    # Keep rows with NaN PDS type and group the rest\n",
    "    nan_rows = df[df[key].isna()]\n",
    "    non_nan_rows = df[df[key].notna()]\n",
    "    if lower_better:\n",
    "        grouped_non_nan = non_nan_rows.groupby(key, as_index=(key==\"PDS type\")).min()\n",
    "    else:\n",
    "        grouped_non_nan = non_nan_rows.groupby(key, as_index=(key==\"PDS type\")).max()\n",
    "    grouped_df = pd.concat([grouped_non_nan, nan_rows])\n",
    "\n",
    "    # to_drop = [\"GradientBoostingRegressor_200\"]\n",
    "    # to_drop = ['MLP3_e700_lr0.001', 'Ridge_10', 'Lasso_e-4', 'RandomForestRegressor_100']\n",
    "    to_drop = ['MLP3_e700_lr0.001', 'Ridge_10', 'Lasso_e-4', \"GradientBoostingRegressor_200\"] # keep only Random Forest\n",
    "    to_drop = [col for col in to_drop if col in grouped_df.columns]\n",
    "    # print(\"DEBUG: Dropping\", to_drop)\n",
    "    grouped_df = grouped_df.drop(columns=to_drop)\n",
    "\n",
    "    # Get the columns to find minimum across\n",
    "    min_cols = ['MLP3_e700_lr0.001', 'Ridge_10', 'Lasso_e-4', 'RandomForestRegressor_100', 'GradientBoostingRegressor_200']\n",
    "    min_cols = [col for col in min_cols if col in grouped_df.columns]\n",
    "\n",
    "    # Find minimum value across specified columns and store in new 'linear' column\n",
    "    if lower_better:\n",
    "        grouped_df['fit'] = grouped_df[min_cols].min(axis=1)\n",
    "    else:\n",
    "        grouped_df['fit'] = grouped_df[min_cols].max(axis=1)\n",
    "\n",
    "    # Drop the original columns\n",
    "    grouped_df = grouped_df.drop(columns=min_cols)\n",
    "\n",
    "    # Drop the stratified and #guiding_models columns since they're no longer meaningful after grouping\n",
    "    for cols_to_drop in ['stratified', '#guiding_models', 'cirt', 'pirt']:\n",
    "        if cols_to_drop == key:\n",
    "            continue\n",
    "        if cols_to_drop in grouped_df.columns:\n",
    "            grouped_df = grouped_df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    return grouped_df, num_anchors\n",
    "\n",
    "\n",
    "def make_df_with_results(table_avg, table_std, bench, split):\n",
    "    cur_methods_for_table = table_avg[bench][split].keys()\n",
    "\n",
    "    df = make_perf_table(\n",
    "        table_avg[bench][split],\n",
    "        table_std[bench][split],\n",
    "        methods=cur_methods_for_table,\n",
    "    )\n",
    "\n",
    "    pd.set_option('display.max_rows', MAX_TABLE_SIZE)\n",
    "    pd.set_option('display.max_columns', MAX_TABLE_SIZE)\n",
    "    pd.set_option(\n",
    "        \"display.max_colwidth\", MAX_TABLE_SIZE\n",
    "    )\n",
    "    for num_samples in df.keys():\n",
    "        # print(\"#anchor_points:\", num_samples)\n",
    "        # Reorder columns to put guiding models, PDS type, and stratified first\n",
    "        cols = df[num_samples].columns.tolist()\n",
    "        first_cols = ['#guiding_models', 'PDS type', 'stratified']\n",
    "        other_cols = [col for col in cols if col not in first_cols]\n",
    "        df[num_samples] = df[num_samples][first_cols + other_cols]\n",
    "\n",
    "        # Replace all values in #guiding_models column with 382\n",
    "        df[num_samples].loc[df[num_samples]['#guiding_models'] == 'all', '#guiding_models'] = 382\n",
    "\n",
    "        # Sort rows by #guiding_models\n",
    "        df[num_samples] = df[num_samples].sort_values(['PDS type', 'stratified', '#guiding_models'])\n",
    "\n",
    "        # print(df[num_samples])\n",
    "\n",
    "    # df[max(list(df.keys()))].to_csv(results_table_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: uncomment all except for num_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:460: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n"
     ]
    }
   ],
   "source": [
    "def process_table_data(\n",
    "    bench,\n",
    "    split,\n",
    "    filename_suffix,\n",
    "    data,\n",
    "    scenarios_to_skip,\n",
    "    ordered,\n",
    "    agg_type,\n",
    "    table_avg_base,\n",
    "    table_std_base,\n",
    "    model_perf_base\n",
    "):\n",
    "    current_table_avg, current_table_std, current_model_perf = make_table_avg(\n",
    "        bench,\n",
    "        split,\n",
    "        filename_suffix,\n",
    "        data,\n",
    "        scenarios_to_skip=scenarios_to_skip,\n",
    "        ordered=ordered,\n",
    "        return_perf_table=True,\n",
    "        agg_type=agg_type\n",
    "    )\n",
    "    table_avg_base = merge_methods(table_avg_base, current_table_avg)\n",
    "    table_std_base = merge_methods(table_std_base, current_table_std)\n",
    "    model_perf_base = merge_methods(model_perf_base, current_model_perf)\n",
    "    return table_avg_base, table_std_base, model_perf_base\n",
    "\n",
    "\n",
    "# load needed results\n",
    "results_suffixes = {\n",
    "    \"mmlu_fields\": {\n",
    "\n",
    "        \"iid\": {\n",
    "            \"ours\": \"_disagreement_best_47\",\n",
    "            \"irt\": \"_disagreement_compare_with_irt43\"\n",
    "        },\n",
    "        # \"noniid\": {\n",
    "        #     \"ours\": \"_disagreement_best_48\",\n",
    "        #     \"irt\": \"_disagreement_compare_with_irt44\"\n",
    "        # } # Old\n",
    "        \"noniid\": {\n",
    "            \"ours\": \"_disagreement_best_68\",\n",
    "            \"irt\": \"_disagreement_compare_with_irt70\"\n",
    "        } # more n anchors (till 2000)\n",
    "    },\n",
    "    \"hellaswag\": {\n",
    "\n",
    "        \"iid\": {\n",
    "            \"ours\": \"_disagreement_best_63\",\n",
    "            \"irt\": \"_disagreement_best_63\"\n",
    "        },\n",
    "        \"noniid\": {\n",
    "            \"ours\": \"_disagreement_best_64\",\n",
    "            \"irt\": \"_disagreement_best_64\"\n",
    "        }\n",
    "    },\n",
    "    \"num_models\": {\n",
    "        3: \"_disagreement_best_57\",\n",
    "        10: \"_disagreement_best_56\",\n",
    "        30: \"_disagreement_best_55\",\n",
    "        100: \"_disagreement_best_54\",\n",
    "        300: \"_disagreement_best_53\",\n",
    "        382: \"_disagreement_best_68\"\n",
    "    },\n",
    "    \"umap_pca\": {\n",
    "        \"no_pca\": \"_disagreement_before_pca_15\",\n",
    "        \"pca1\": \"_disagreement_umap_pca88\",\n",
    "        \"pca2\": \"_disagreement_umap_pca87\",\n",
    "        \"pca4\": \"_disagreement_umap_pca86\",\n",
    "        \"pca8\": \"_disagreement_umap_pca85\",\n",
    "        \"pca16\": \"_disagreement_umap_pca78\",\n",
    "        \"pca32\": \"_disagreement_umap_pca77\",\n",
    "        \"pca64\": \"_disagreement_umap_pca21\",\n",
    "        \"pca128\": \"_disagreement_umap_pca23\",\n",
    "        # \"pca256\": \"_disagreement_umap_pca25\",\n",
    "        \"pca256\": \"_disagreement_best_68\",\n",
    "        \"pca300\": \"_disagreement_umap_pca79\",\n",
    "        \"umap64\": \"_disagreement_umap_pca27\",\n",
    "        \"umap128\": \"_disagreement_umap_pca29\",\n",
    "        \"umap256\": \"_disagreement_umap_pca31\"\n",
    "    },\n",
    "    \"prediction_strategy\": {\n",
    "        \"linear\": \"_disagreement_before_pca_73\",\n",
    "        \"mlps\": \"_disagreement_before_pca_82\",\n",
    "        \"other\": \"_disagreement_best_68\",\n",
    "    }\n",
    "}\n",
    "# print(\"DEBUG: uncomment all except for num_models\")\n",
    "scenarios_to_skip = []\n",
    "table_1_data = []\n",
    "table_1_data_iid = []\n",
    "figure_n_anchors_data = {}\n",
    "umap_pca_dfs = {}\n",
    "prediction_strategy_dfs = {}\n",
    "\n",
    "table_avg_dict = {}\n",
    "table_std_dict = {}\n",
    "model_perf_dict = {}\n",
    "\n",
    "for bench, per_bench in results_suffixes.items():\n",
    "    if bench not in table_avg_dict:\n",
    "        table_avg_dict[bench] = {}\n",
    "        table_std_dict[bench] = {}\n",
    "        model_perf_dict[bench] = {}\n",
    "    # ordered = bench in [\"mmlu_fields\", \"hellaswag\", \"num_models\", \"umap_pca\"]\n",
    "    ordered = True\n",
    "    for agg_type in [\"mae\", \"rank\"]:\n",
    "\n",
    "        if agg_type not in table_avg_dict[bench]:\n",
    "            table_avg_dict[bench][agg_type] = {}\n",
    "            table_std_dict[bench][agg_type] = {}\n",
    "            model_perf_dict[bench][agg_type] = {}\n",
    "\n",
    "        if bench in [\"num_models\", \"umap_pca\", \"prediction_strategy\"]:\n",
    "            if agg_type == \"mae\" and bench not in [\"umap_pca\", \"prediction_strategy\"]:\n",
    "                continue\n",
    "\n",
    "            split = \"noniid\"\n",
    "            real_bench = \"mmlu_fields\"\n",
    "\n",
    "            factor_list = []\n",
    "            for factor, filename_suffix in per_bench.items():\n",
    "\n",
    "                table_avg_base = None\n",
    "                table_std_base = None\n",
    "                model_perf_base = None\n",
    "\n",
    "                if factor not in table_avg_dict[bench]:\n",
    "                    table_avg_dict[bench][factor] = {}\n",
    "                    table_std_dict[bench][factor] = {}\n",
    "                    model_perf_dict[bench][factor] = {}\n",
    "\n",
    "                results_path = f'results/accs_{real_bench}_split-{split}_iterations-5{filename_suffix}.pickle'\n",
    "\n",
    "                data = load_pickle(results_path)\n",
    "\n",
    "                table_avg_base, table_std_base, model_perf_base = process_table_data(\n",
    "                    real_bench,\n",
    "                    split,\n",
    "                    filename_suffix,\n",
    "                    data,\n",
    "                    scenarios_to_skip,\n",
    "                    ordered,\n",
    "                    agg_type,\n",
    "                    table_avg_base,\n",
    "                    table_std_base,\n",
    "                    model_perf_base\n",
    "                )\n",
    "\n",
    "                table_avg_dict[bench][agg_type][factor] = table_avg_base\n",
    "                table_std_dict[bench][agg_type][factor] = table_std_base\n",
    "                model_perf_dict[bench][agg_type][factor] = model_perf_base\n",
    "\n",
    "                df = make_df_with_results(table_avg_base, table_std_base, real_bench, split)\n",
    "\n",
    "                if bench == \"prediction_strategy\":\n",
    "\n",
    "                    filtered_df = df[100]\n",
    "\n",
    "                    filtered_df = filtered_df[filtered_df['PDS type'] == 'highest']\n",
    "                    if factor == \"other\":\n",
    "                        if agg_type == \"rank\":\n",
    "                            filtered_df = filtered_df.loc[filtered_df['RandomForestRegressor_100'].idxmax()].to_frame().T\n",
    "                        else:\n",
    "                            filtered_df = filtered_df.loc[filtered_df['RandomForestRegressor_100'].idxmin()].to_frame().T\n",
    "\n",
    "                        filtered_df.drop(columns=['MLP3_e700_lr0.001'], inplace=True)\n",
    "                    else:\n",
    "                        assert factor in [\"linear\", \"mlps\"]\n",
    "                        if agg_type == \"rank\":\n",
    "                            filtered_df = pd.DataFrame([filtered_df.max()], index=['highest'])\n",
    "                        else:\n",
    "                            filtered_df = pd.DataFrame([filtered_df.min()], index=['highest'])\n",
    "\n",
    "                        if factor == \"linear\":\n",
    "                            filtered_df = filtered_df[[\"LinearRegression\"]]\n",
    "                        else:\n",
    "                            assert factor == \"mlps\"\n",
    "                            filtered_df = filtered_df[[\"MLP2_e200_lr0.001\", \"MLP3_e700_lr0.001\"]]\n",
    "\n",
    "                    cols_to_drop = ['PDS type', 'stratified', '#guiding_models']\n",
    "                    cols_to_drop = [col for col in cols_to_drop if col in filtered_df.columns]\n",
    "                    filtered_df.drop(columns=cols_to_drop, inplace=True)\n",
    "                    factor_list.append(filtered_df)\n",
    "                else:\n",
    "                    grouped_df, _ = extract_data_for_table_1(df, num_anchors=100, lower_better=(agg_type == \"mae\"))\n",
    "                    grouped_df = grouped_df[[\"fit\"]].rename(columns={\"fit\": f\"fit-{factor}\"})\n",
    "                    factor_list.append(grouped_df)\n",
    "\n",
    "            if len(factor_list) > 0:\n",
    "\n",
    "                factor_df = pd.concat(factor_list, axis=1)\n",
    "\n",
    "                if bench == \"num_models\":\n",
    "                    num_models_df = factor_df\n",
    "\n",
    "                if bench == \"prediction_strategy\":\n",
    "                    prediction_strategy_dfs[agg_type] = factor_df\n",
    "\n",
    "                if bench == \"umap_pca\":\n",
    "                    umap_pca_dfs[agg_type] = factor_df\n",
    "        else:\n",
    "\n",
    "            for split, per_split in per_bench.items():\n",
    "                if split not in table_avg_dict[bench][agg_type]:\n",
    "                    table_avg_dict[bench][agg_type][split] = {}\n",
    "                    table_std_dict[bench][agg_type][split] = {}\n",
    "                    model_perf_dict[bench][agg_type][split] = {}\n",
    "\n",
    "                table_avg_base = None\n",
    "                table_std_base = None\n",
    "                model_perf_base = None\n",
    "                for method in [\n",
    "                    \"ours\",\n",
    "                    \"irt\"\n",
    "                ]:\n",
    "\n",
    "                    filename_suffix = per_split[method]\n",
    "                    results_path = f'results/accs_{bench}_split-{split}_iterations-5{filename_suffix}.pickle'\n",
    "                    data = load_pickle(results_path)\n",
    "\n",
    "                    table_avg_base, table_std_base, model_perf_base = process_table_data(\n",
    "                        bench,\n",
    "                        split,\n",
    "                        filename_suffix,\n",
    "                        data,\n",
    "                        scenarios_to_skip,\n",
    "                        ordered,\n",
    "                        agg_type,\n",
    "                        table_avg_base,\n",
    "                        table_std_base,\n",
    "                        model_perf_base\n",
    "                    )\n",
    "\n",
    "                table_avg_dict[bench][agg_type][split] = table_avg_base\n",
    "                table_std_dict[bench][agg_type][split] = table_std_base\n",
    "                model_perf_dict[bench][agg_type][split] = model_perf_base\n",
    "\n",
    "                if split == \"noniid\":\n",
    "\n",
    "                    df = make_df_with_results(table_avg_base, table_std_base, bench, split)\n",
    "                    table_1_data.append(extract_data_for_table_1(df, num_anchors=100, lower_better=(agg_type == \"mae\")))\n",
    "                    for num_anchors in df.keys():\n",
    "                        if num_anchors not in figure_n_anchors_data:\n",
    "                            figure_n_anchors_data[num_anchors] = []\n",
    "                        figure_n_anchors_data[num_anchors].append(extract_data_for_table_1(df, num_anchors=num_anchors, lower_better=(agg_type == \"mae\")))\n",
    "                    if agg_type == \"rank\":\n",
    "                        ablation_strat, _ = extract_data_for_table_1(df, num_anchors=100, lower_better=(agg_type == \"mae\"), key=\"stratified\")\n",
    "                if split == \"iid\":\n",
    "                    df_iid = make_df_with_results(table_avg_base, table_std_base, bench, split)\n",
    "                    table_1_data_iid.append(extract_data_for_table_1(df_iid, num_anchors=100, lower_better=(agg_type == \"mae\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP3_e700_lr0.001</th>\n",
       "      <th>Ridge_10</th>\n",
       "      <th>Lasso_e-4</th>\n",
       "      <th>RandomForestRegressor_100</th>\n",
       "      <th>GradientBoostingRegressor_200</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>perfect_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high-disagreement@2</th>\n",
       "      <td>0.106764</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>0.018907</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        naive       KNN MLP3_e700_lr0.001  Ridge_10 Lasso_e-4  \\\n",
       "high-disagreement@2  0.106764  0.015482          0.041638  0.018907  0.018902   \n",
       "\n",
       "                    RandomForestRegressor_100 GradientBoostingRegressor_200  \\\n",
       "high-disagreement@2                  0.010688                      0.013102   \n",
       "\n",
       "                    mean_train_score perfect_knn  \n",
       "high-disagreement@2              NaN         NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_strategy_dfs['mae']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_1, latex_str = make_table_1(table_1_data + [(None, 100), (None, 100)])\n",
    "table_1, latex_str = make_table_1(table_1_data)\n",
    "display(table_1)\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_1, latex_str = make_table_1(table_1_data + [(None, 100), (None, 100)])\n",
    "table_1_iid, latex_str_iid = make_table_1(table_1_data_iid)\n",
    "display(table_1_iid)\n",
    "print(latex_str_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity: Num source models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1918859/3988414588.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  display(num_models_df.applymap(prepare_rank))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit-3</th>\n",
       "      <th>fit-10</th>\n",
       "      <th>fit-30</th>\n",
       "      <th>fit-100</th>\n",
       "      <th>fit-300</th>\n",
       "      <th>fit-382</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowest</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fit-3  fit-10  fit-30  fit-100  fit-300  fit-382\n",
       "highest  0.652   0.787   0.844    0.969    0.975    0.987\n",
       "lowest   0.475   0.592   0.735    0.915    0.898    0.884\n",
       "random   0.583   0.775   0.817    0.917    0.921    0.933\n",
       "-          NaN     NaN     NaN      NaN      NaN      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(num_models_df.applymap(prepare_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: prediction strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>MLP2_e200_lr0.001</th>\n",
       "      <th>MLP3_e700_lr0.001</th>\n",
       "      <th>naive</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Ridge_10</th>\n",
       "      <th>Lasso_e-4</th>\n",
       "      <th>RandomForestRegressor_100</th>\n",
       "      <th>GradientBoostingRegressor_200</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>perfect_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>0.887805</td>\n",
       "      <td>0.959437</td>\n",
       "      <td>0.962139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high-disagreement@100+nonstratified</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956306</td>\n",
       "      <td>0.97138</td>\n",
       "      <td>0.918199</td>\n",
       "      <td>0.908068</td>\n",
       "      <td>0.987355</td>\n",
       "      <td>0.979625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     LinearRegression  MLP2_e200_lr0.001  \\\n",
       "highest                                      0.887805           0.959437   \n",
       "high-disagreement@100+nonstratified               NaN                NaN   \n",
       "\n",
       "                                     MLP3_e700_lr0.001     naive      KNN  \\\n",
       "highest                                       0.962139       NaN      NaN   \n",
       "high-disagreement@100+nonstratified                NaN  0.956306  0.97138   \n",
       "\n",
       "                                     Ridge_10 Lasso_e-4  \\\n",
       "highest                                   NaN       NaN   \n",
       "high-disagreement@100+nonstratified  0.918199  0.908068   \n",
       "\n",
       "                                    RandomForestRegressor_100  \\\n",
       "highest                                                   NaN   \n",
       "high-disagreement@100+nonstratified                  0.987355   \n",
       "\n",
       "                                    GradientBoostingRegressor_200  \\\n",
       "highest                                                       NaN   \n",
       "high-disagreement@100+nonstratified                      0.979625   \n",
       "\n",
       "                                    mean_train_score perfect_knn  \n",
       "highest                                          NaN         NaN  \n",
       "high-disagreement@100+nonstratified              NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(prediction_strategy_dfs['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>MLP2_e200_lr0.001</th>\n",
       "      <th>MLP3_e700_lr0.001</th>\n",
       "      <th>naive</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP3_e700_lr0.001</th>\n",
       "      <th>Ridge_10</th>\n",
       "      <th>Lasso_e-4</th>\n",
       "      <th>RandomForestRegressor_100</th>\n",
       "      <th>GradientBoostingRegressor_200</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>perfect_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>0.029536</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>0.01582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high-disagreement@2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106764</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>0.018907</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     LinearRegression  MLP2_e200_lr0.001 MLP3_e700_lr0.001  \\\n",
       "highest                      0.029536           0.017351           0.01582   \n",
       "high-disagreement@2               NaN                NaN               NaN   \n",
       "\n",
       "                        naive       KNN MLP3_e700_lr0.001  Ridge_10 Lasso_e-4  \\\n",
       "highest                   NaN       NaN               NaN       NaN       NaN   \n",
       "high-disagreement@2  0.106764  0.015482          0.041638  0.018907  0.018902   \n",
       "\n",
       "                    RandomForestRegressor_100 GradientBoostingRegressor_200  \\\n",
       "highest                                   NaN                           NaN   \n",
       "high-disagreement@2                  0.010688                      0.013102   \n",
       "\n",
       "                    mean_train_score perfect_knn  \n",
       "highest                          NaN         NaN  \n",
       "high-disagreement@2              NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(prediction_strategy_dfs['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit-no_pca</th>\n",
       "      <th>fit-pca1</th>\n",
       "      <th>fit-pca2</th>\n",
       "      <th>fit-pca4</th>\n",
       "      <th>fit-pca8</th>\n",
       "      <th>fit-pca16</th>\n",
       "      <th>fit-pca32</th>\n",
       "      <th>fit-pca64</th>\n",
       "      <th>fit-pca128</th>\n",
       "      <th>fit-pca256</th>\n",
       "      <th>fit-pca300</th>\n",
       "      <th>fit-umap64</th>\n",
       "      <th>fit-umap128</th>\n",
       "      <th>fit-umap256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>0.917974</td>\n",
       "      <td>0.88597</td>\n",
       "      <td>0.966604</td>\n",
       "      <td>0.976998</td>\n",
       "      <td>0.978612</td>\n",
       "      <td>0.982702</td>\n",
       "      <td>0.983227</td>\n",
       "      <td>0.987129</td>\n",
       "      <td>0.986717</td>\n",
       "      <td>0.987355</td>\n",
       "      <td>0.985103</td>\n",
       "      <td>0.981726</td>\n",
       "      <td>0.969681</td>\n",
       "      <td>0.969944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowest</th>\n",
       "      <td>0.909869</td>\n",
       "      <td>0.647004</td>\n",
       "      <td>0.81621</td>\n",
       "      <td>0.831895</td>\n",
       "      <td>0.90045</td>\n",
       "      <td>0.907242</td>\n",
       "      <td>0.899925</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.884278</td>\n",
       "      <td>0.880525</td>\n",
       "      <td>0.895985</td>\n",
       "      <td>0.877261</td>\n",
       "      <td>0.905478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.902702</td>\n",
       "      <td>0.739066</td>\n",
       "      <td>0.877936</td>\n",
       "      <td>0.926754</td>\n",
       "      <td>0.941088</td>\n",
       "      <td>0.93666</td>\n",
       "      <td>0.931445</td>\n",
       "      <td>0.934897</td>\n",
       "      <td>0.935084</td>\n",
       "      <td>0.933021</td>\n",
       "      <td>0.930131</td>\n",
       "      <td>0.913734</td>\n",
       "      <td>0.922777</td>\n",
       "      <td>0.9203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit-no_pca  fit-pca1  fit-pca2  fit-pca4  fit-pca8 fit-pca16  \\\n",
       "highest   0.917974   0.88597  0.966604  0.976998  0.978612  0.982702   \n",
       "lowest    0.909869  0.647004   0.81621  0.831895   0.90045  0.907242   \n",
       "random    0.902702  0.739066  0.877936  0.926754  0.941088   0.93666   \n",
       "-             None      None      None      None      None      None   \n",
       "\n",
       "        fit-pca32 fit-pca64 fit-pca128 fit-pca256 fit-pca300 fit-umap64  \\\n",
       "highest  0.983227  0.987129   0.986717   0.987355   0.985103   0.981726   \n",
       "lowest   0.899925  0.903039   0.894071   0.884278   0.880525   0.895985   \n",
       "random   0.931445  0.934897   0.935084   0.933021   0.930131   0.913734   \n",
       "-            None      None       None       None       None       None   \n",
       "\n",
       "        fit-umap128 fit-umap256  \n",
       "highest    0.969681    0.969944  \n",
       "lowest     0.877261    0.905478  \n",
       "random     0.922777      0.9203  \n",
       "-              None        None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(umap_pca_dfs['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit-no_pca</th>\n",
       "      <th>fit-pca1</th>\n",
       "      <th>fit-pca2</th>\n",
       "      <th>fit-pca4</th>\n",
       "      <th>fit-pca8</th>\n",
       "      <th>fit-pca16</th>\n",
       "      <th>fit-pca32</th>\n",
       "      <th>fit-pca64</th>\n",
       "      <th>fit-pca128</th>\n",
       "      <th>fit-pca256</th>\n",
       "      <th>fit-pca300</th>\n",
       "      <th>fit-umap64</th>\n",
       "      <th>fit-umap128</th>\n",
       "      <th>fit-umap256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.037643</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>0.01133</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>0.014032</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.017334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowest</th>\n",
       "      <td>0.021754</td>\n",
       "      <td>0.055548</td>\n",
       "      <td>0.033483</td>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.021407</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>0.021846</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.024165</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.020008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.022871</td>\n",
       "      <td>0.040245</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.01642</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>0.017306</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.018146</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.018426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit-no_pca  fit-pca1  fit-pca2  fit-pca4  fit-pca8 fit-pca16  \\\n",
       "highest   0.018456  0.037643  0.015711  0.012556  0.010903   0.01133   \n",
       "lowest    0.021754  0.055548  0.033483  0.026182    0.0219  0.021407   \n",
       "random    0.022871  0.040245  0.023561  0.018476   0.01642  0.017026   \n",
       "-             None      None      None      None      None      None   \n",
       "\n",
       "        fit-pca32 fit-pca64 fit-pca128 fit-pca256 fit-pca300 fit-umap64  \\\n",
       "highest  0.010243  0.010467   0.010639   0.010688   0.011015   0.014032   \n",
       "lowest   0.022114  0.021846   0.022926   0.024165   0.024441   0.022801   \n",
       "random   0.017931  0.017306   0.017523   0.018146   0.018525   0.018666   \n",
       "-            None      None       None       None       None       None   \n",
       "\n",
       "        fit-umap128 fit-umap256  \n",
       "highest    0.015574    0.017334  \n",
       "lowest     0.022306    0.020008  \n",
       "random     0.017787    0.018426  \n",
       "-              None        None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(umap_pca_dfs['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation: Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ablation_strat.loc[~ablation_strat['stratified'].isna(), ('fit', 'stratified')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure correlation with gt performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_with_gt_performance(model_perf_dict):\n",
    "    # if results == 'acc':\n",
    "    #     if agg == 'leaderboard':\n",
    "    # split = 'noniid'\n",
    "    split = 'noniid'\n",
    "    iteration = 1\n",
    "    number_item = 100\n",
    "    color_mappings = {}\n",
    "\n",
    "    alphas = {'random_naive':.4,'anchor_naive':.4,'anchor-irt_naive':.4,'anchor-irt_gpirt':.8}\n",
    "    markersize = {'random_naive':7,'anchor_naive':5,'anchor-irt_naive':5,'anchor-irt_gpirt':5}\n",
    "    names = {\n",
    "        'random_naive':'random',\n",
    "        'anchor-irt_naive':'IRT ',\n",
    "        'anchor_naive':'correctness',\n",
    "        'anchor-irt_gpirt':'IRT++',\n",
    "        'high-disagreement@100+nonstratified_GradientBoostingRegressor_200': 'High PDS/Linear',\n",
    "        'high-disagreement@100+nonstratified_RandomForestRegressor_100': 'High PDS/Random Forest'\n",
    "    }\n",
    "    plt.figure(figsize=(1.2*3.5,1.2*3))\n",
    "\n",
    "    # for i,bench in enumerate(['mmlu']): #benchs[:4]\n",
    "    for i,bench in enumerate(['mmlu_fields']): #benchs[:4]\n",
    "        # axis = {'lb':'avg. score', 'mmlu_fields':'accuracy', 'mmlu':'accuracy', 'helm':'mean win rate', 'alpaca':'win rate'}\n",
    "        # for method in ['anchor-irt_gpirt']: #\n",
    "\n",
    "        for method in [\n",
    "            # 'random_KNN'\n",
    "            # 'high-disagreement@100+nonstratified_GradientBoostingRegressor_200'\n",
    "            # 'high-disagreement+nonstratified_RandomForestRegressor_100'\n",
    "            'high-disagreement@100+nonstratified_RandomForestRegressor_100'\n",
    "        ]: #\n",
    "            # print(model_perf[bench][split][method])\n",
    "            if model_perf_dict is None:\n",
    "                print(\"Using hardcoded data\")\n",
    "                x = [\n",
    "                    0.74505765, 0.57627382, 0.63675495, 0.65292241, 0.38084539, 0.64716621,\n",
    "                    0.60905773, 0.64266456, 0.77400765, 0.65963511, 0.45349487, 0.53712371,\n",
    "                    0.54949706, 0.65399154, 0.66097766, 0.70370242, 0.60520878, 0.56062885,\n",
    "                    0.62193137, 0.63557209, 0.39394311, 0.457429, 0.33628442, 0.60314194,\n",
    "                    0.63755535, 0.62489059, 0.62572778, 0.76651098, 0.61419194, 0.64899013,\n",
    "                    0.65274401, 0.50838601, 0.77287346, 0.70602432, 0.54623595, 0.74655344,\n",
    "                    0.71878393, 0.63617809, 0.76029052, 0.75110232\n",
    "                ]\n",
    "                y = [\n",
    "                    0.75731513, 0.60630879, 0.63863409, 0.66208239, 0.38429752, 0.64862158,\n",
    "                    0.6141397, 0.63641627, 0.72950503, 0.65494508, 0.39609827, 0.54465079,\n",
    "                    0.55145108, 0.64995122, 0.6629164, 0.7023732, 0.62522846, 0.54741339,\n",
    "                    0.63129268, 0.6264134, 0.41973213, 0.51171946, 0.35283553, 0.60904086,\n",
    "                    0.63357007, 0.62456882, 0.62493765, 0.76117544, 0.62270945, 0.63739011,\n",
    "                    0.64783929, 0.49335064, 0.75879076, 0.72244666, 0.56023766, 0.74885069,\n",
    "                    0.7073013, 0.6313948, 0.70250782, 0.75130385\n",
    "                ]\n",
    "            else:\n",
    "                model_perf = model_perf_dict[bench]['mae'][split]\n",
    "                x,y = model_perf[bench][split]['truth'], model_perf[bench][split][method][number_item][:,iteration]\n",
    "                print(x)\n",
    "                print(y)\n",
    "            method_name = names[method] if method in names else method\n",
    "            # label = \"{:} (error={:.3f}, $r_S$={:.2f})\".format(method_name, np.abs(x-y).mean(), stats.spearmanr(x,y).statistic)\n",
    "            label = \"{:} ($r_S$={:.2f})\".format(method_name, stats.spearmanr(x,y).statistic)\n",
    "            markersize = markersize[method] if method in markersize else 5\n",
    "            alpha = alphas[method] if method in alphas else 0.5\n",
    "            color = color_mappings[method] if method in color_mappings else 'black'\n",
    "            plt.plot(x, y, 'o', label = label, markersize=markersize,alpha=alpha, color=color)\n",
    "\n",
    "        plt.legend(fontsize=10, framealpha=.9)\n",
    "        #plt.title(titles[bench])\n",
    "        plt.plot([0,1],[0,1],'--r',lw=.5)\n",
    "        plt.grid(alpha=.2)\n",
    "        plt.xlabel('Ground truth performance', size=12)\n",
    "        plt.ylabel('Estimated performance', size=12)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(0,1)\n",
    "        tick_label_size = 11  # Example size, adjust as needed\n",
    "        plt.tick_params(axis='x', labelsize=tick_label_size)\n",
    "        plt.tick_params(axis='y', labelsize=tick_label_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_FOLDER, 'performance_correlation_mmlu.pdf'), bbox_inches='tight', dpi=400, transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_with_gt_performance(model_perf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_with_gt_performance(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from scipy import stats\n",
    "# import sys\n",
    "# import subprocess\n",
    "\n",
    "\n",
    "def make_figure_language_scatterplot(model_perf_dict):\n",
    "    # Define absolute paths\n",
    "    # script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    # repo_root = os.path.abspath(os.path.join(script_dir, \"../..\"))  # Go up two levels to get to repo root\n",
    "    output_file = os.path.join(FIGURES_FOLDER, \"language_scatterplot/plot.pdf\")\n",
    "    method = 'high-disagreement@100+nonstratified_RandomForestRegressor_100'\n",
    "\n",
    "    # print(f\"Script directory: {script_dir}\")\n",
    "    # print(f\"Repository root: {repo_root}\")\n",
    "    # print(f\"Output will be saved to: {output_file}\")\n",
    "\n",
    "    # Since model_perf_dict is referenced but not defined, we'll just use the hardcoded values\n",
    "    # that are already in the script\n",
    "    # model_perf_dict = {\n",
    "    #     'mmlu_fields': {\n",
    "    #         'noniid': {\n",
    "    #             'mae': {}  # This is referenced but not used in final plotting\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "\n",
    "    # hardcoded version\n",
    "    split = 'noniid'\n",
    "    iteration = 1\n",
    "    number_item = 100\n",
    "    color_mappings = {}\n",
    "\n",
    "    alphas = {'random_naive':.3,'anchor_naive':.3,'anchor-irt_naive':.3,'anchor-irt_gpirt':.6}\n",
    "    markersize = {'random_naive':9,'anchor_naive':7,'anchor-irt_naive':7,'anchor-irt_gpirt':7}\n",
    "    names = {\n",
    "        'random_naive':'random',\n",
    "        'anchor-irt_naive':'IRT ',\n",
    "        'anchor_naive':'correctness',\n",
    "        'anchor-irt_gpirt':'IRT++',\n",
    "        'high-disagreement@100+nonstratified_GradientBoostingRegressor_200': 'High PDS / Signature-GB (DISCO)',\n",
    "        'high-disagreement@100+nonstratified_RandomForestRegressor_100': 'High PDS / Signature-RF (DISCO)'\n",
    "    }\n",
    "    plt.figure(figsize=(1.2*3.5,1.2*3))\n",
    "\n",
    "    # for i,bench in enumerate(['mmlu']): #benchs[:4]\n",
    "    for i,bench in enumerate(['mmlu_fields']): #benchs[:4]\n",
    "        axis = {'lb':'avg. score', 'mmlu_fields':'accuracy', 'mmlu':'accuracy', 'helm':'mean win rate', 'alpaca':'win rate'}\n",
    "        # for method in ['anchor-irt_gpirt']: #\n",
    "        # model_perf = model_perf_dict[bench][split]['mae']\n",
    "\n",
    "        # Plot the x=y line behind the points\n",
    "        plt.plot([0.3,0.8],[0.3,0.8],'--r',lw=.5, zorder=0)\n",
    "\n",
    "        # for method in [\n",
    "        #     # 'random_KNN'\n",
    "        #     'high-disagreement@100+nonstratified_GradientBoostingRegressor_200'\n",
    "        # ]: #\n",
    "        # print(model_perf[bench][split][method])\n",
    "        # x = [\n",
    "        #     0.74505765, 0.57627382, 0.63675495, 0.65292241, 0.38084539, 0.64716621,\n",
    "        #     0.60905773, 0.64266456, 0.77400765, 0.65963511, 0.45349487, 0.53712371,\n",
    "        #     0.54949706, 0.65399154, 0.66097766, 0.70370242, 0.60520878, 0.56062885,\n",
    "        #     0.62193137, 0.63557209, 0.39394311, 0.457429, 0.33628442, 0.60314194,\n",
    "        #     0.63755535, 0.62489059, 0.62572778, 0.76651098, 0.61419194, 0.64899013,\n",
    "        #     0.65274401, 0.50838601, 0.77287346, 0.70602432, 0.54623595, 0.74655344,\n",
    "        #     0.71878393, 0.63617809, 0.76029052, 0.75110232\n",
    "        # ]\n",
    "        # y = [\n",
    "        #     0.74162506, 0.58105963, 0.62999359, 0.65297844, 0.38183675, 0.64818,\n",
    "        #     0.62059757, 0.6415032, 0.73112584, 0.65266202, 0.42390838, 0.54364333,\n",
    "        #     0.55297843, 0.64760771, 0.66037917, 0.71506391, 0.62563429, 0.55669639,\n",
    "        #     0.63069553, 0.62085096, 0.40288662, 0.48256168, 0.34233494, 0.6123069,\n",
    "        #     0.6299206, 0.62039802, 0.61374431, 0.75969047, 0.62258986, 0.64948626,\n",
    "        #     0.63557096, 0.48961551, 0.76773106, 0.68572294, 0.55060159, 0.74863011,\n",
    "        #     0.71897123, 0.61933916, 0.70531546, 0.74709759\n",
    "        # ]\n",
    "        if model_perf_dict is None:\n",
    "            print(\"Using hardcoded data\")\n",
    "            # x = [\n",
    "            #     0.74505765, 0.57627382, 0.63675495, 0.65292241, 0.38084539, 0.64716621,\n",
    "            #     0.60905773, 0.64266456, 0.77400765, 0.65963511, 0.45349487, 0.53712371,\n",
    "            #     0.54949706, 0.65399154, 0.66097766, 0.70370242, 0.60520878, 0.56062885,\n",
    "            #     0.62193137, 0.63557209, 0.39394311, 0.457429, 0.33628442, 0.60314194,\n",
    "            #     0.63755535, 0.62489059, 0.62572778, 0.76651098, 0.61419194, 0.64899013,\n",
    "            #     0.65274401, 0.50838601, 0.77287346, 0.70602432, 0.54623595, 0.74655344,\n",
    "            #     0.71878393, 0.63617809, 0.76029052, 0.75110232\n",
    "            # ]\n",
    "            # y = [\n",
    "            #     0.75731513, 0.60630879, 0.63863409, 0.66208239, 0.38429752, 0.64862158,\n",
    "            #     0.6141397, 0.63641627, 0.72950503, 0.65494508, 0.39609827, 0.54465079,\n",
    "            #     0.55145108, 0.64995122, 0.6629164, 0.7023732, 0.62522846, 0.54741339,\n",
    "            #     0.63129268, 0.6264134, 0.41973213, 0.51171946, 0.35283553, 0.60904086,\n",
    "            #     0.63357007, 0.62456882, 0.62493765, 0.76117544, 0.62270945, 0.63739011,\n",
    "            #     0.64783929, 0.49335064, 0.75879076, 0.72244666, 0.56023766, 0.74885069,\n",
    "            #     0.7073013, 0.6313948, 0.70250782, 0.75130385\n",
    "            # ]\n",
    "            x = [0.74505765, 0.57627382, 0.63675495, 0.65292241, 0.38084539, 0.64716621,\n",
    "                0.60905773, 0.64266456, 0.77400765, 0.65963511, 0.45349487, 0.53712371,\n",
    "                0.54949706, 0.65399154, 0.66097766, 0.70370242, 0.60520878, 0.56062885,\n",
    "                0.62193137, 0.63557209, 0.39394311, 0.457429, 0.33628442, 0.60314194,\n",
    "                0.63755535, 0.62489059, 0.62572778, 0.76651098, 0.61419194, 0.64899013,\n",
    "                0.65274401, 0.50838601, 0.77287346, 0.70602432, 0.54623595, 0.74655344,\n",
    "                0.71878393, 0.63617809, 0.76029052, 0.75110232]\n",
    "            y = [0.75731513, 0.60630879, 0.63863409, 0.66208239, 0.38429752, 0.64862158,\n",
    "                0.6141397, 0.63641627, 0.72950503, 0.65494508, 0.39609827, 0.54465079,\n",
    "                0.55145108, 0.64995122, 0.6629164, 0.7023732, 0.62522846, 0.54741339,\n",
    "                0.63129268, 0.6264134, 0.41973213, 0.51171946, 0.35283553, 0.60904086,\n",
    "                0.63357007, 0.62456882, 0.62493765, 0.76117544, 0.62270945, 0.63739011,\n",
    "                0.64783929, 0.49335064, 0.75879076, 0.72244666, 0.56023766, 0.74885069,\n",
    "                0.7073013, 0.6313948, 0.70250782, 0.75130385]\n",
    "        else:\n",
    "\n",
    "            model_perf = model_perf_dict[bench]['mae'][split]\n",
    "            x,y = model_perf[bench][split]['truth'], model_perf[bench][split][method][number_item][:,iteration]\n",
    "            print(x)\n",
    "            print(y)\n",
    "        method_name = names[method] if method in names else method\n",
    "\n",
    "        # Calculate Spearman and Pearson correlations\n",
    "        spearman_corr = stats.spearmanr(x, y).statistic\n",
    "        pearson_corr = stats.pearsonr(x, y).statistic\n",
    "\n",
    "        label = \"{:}\\nSpearman={:.3f}\\nPearson={:.3f}\".format(\n",
    "            method_name,\n",
    "            spearman_corr,\n",
    "            pearson_corr\n",
    "        )\n",
    "\n",
    "        marker_size = markersize[method] if method in markersize else 7\n",
    "        alpha = alphas[method] if method in alphas else 0.4\n",
    "        color = color_mappings[method] if method in color_mappings else 'black'\n",
    "        plt.plot(x, y, 'o', label=label, markersize=marker_size, alpha=alpha, color=color, markeredgewidth=0, zorder=1)\n",
    "\n",
    "        # Add the correlation values as text in the plot\n",
    "        plt.legend(fontsize=10, framealpha=0, frameon=False, handlelength=0, handletextpad=0, markerscale=0, loc='upper left')\n",
    "        #plt.title(titles[bench])\n",
    "        plt.grid(alpha=.2)\n",
    "        plt.xlabel('True accuracy', size=12)\n",
    "        plt.ylabel('Estimated accuracy', size=12)\n",
    "        plt.xlim(0.3, 0.8)\n",
    "        plt.ylim(0.3, 0.8)\n",
    "        tick_label_size = 11  # Example size, adjust as needed\n",
    "        plt.tick_params(axis='x', labelsize=tick_label_size)\n",
    "        plt.tick_params(axis='y', labelsize=tick_label_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, bbox_inches='tight', dpi=400, transparent=True)\n",
    "    print(f\"Plot saved to: {output_file}\")\n",
    "\n",
    "# # Crop the PDF using pdfcrop\n",
    "# try:\n",
    "#     subprocess.run(['pdfcrop', output_file, output_file], check=True)\n",
    "#     print(f\"PDF cropped successfully: {output_file}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error cropping PDF: {e}\")\n",
    "#     print(\"If pdfcrop is not installed, you can install it with:\")\n",
    "#     print(\"  - On macOS: 'brew install texlive' or through MacTex\")\n",
    "#     print(\"  - On Linux: 'apt-get install texlive-extra-utils'\")\n",
    "#     print(\"  - On Windows: Install MiKTeX or TeX Live which includes pdfcrop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_figure_language_scatterplot(model_perf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_figure_language_scatterplot(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure: n_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_figure_n_anchors(figure_n_anchors_data):\n",
    "    maes = {}\n",
    "    ranks = {}\n",
    "    num_anchors_axis = []\n",
    "    for method in [\n",
    "        \"DISCO + Random Forest (ours)\",\n",
    "        \"DISCO + kNN (ours)\",\n",
    "        \"Random + Eval\",\n",
    "        \"Random + Random Forest\",\n",
    "        \"Anchor-correctness + gp-IRT\"\n",
    "    ]:\n",
    "        maes[method] = []\n",
    "        ranks[method] = []\n",
    "    if figure_n_anchors_data is None:\n",
    "        print(\"Using hardcoded data\")\n",
    "        ranks = {\n",
    "            'DISCO + Random Forest (ours)': [0.96, 0.977, 0.981, 0.987, 0.977, 0.985, 0.984, 0.979],\n",
    "            'DISCO + kNN (ours)': [0.973, 0.975, 0.973, 0.972, 0.974, 0.957, 0.952, 0.95],\n",
    "            'Random + Eval': [0.574, 0.721, 0.865, 0.916, 0.944, 0.972, 0.988, 0.992],\n",
    "            'Random + Random Forest': [0.824, 0.866, 0.901, 0.933, 0.928, 0.932, 0.952, 0.959],\n",
    "            'Anchor-correctness + gp-IRT': [0.845, 0.882, 0.925, 0.927, 0.956, 0.974, 0.991, 0.996]}\n",
    "        maes = {\n",
    "            'DISCO + Random Forest (ours)': [2.05, 1.2, 1.16, 1.07, 1.08, 1.02, 0.93, 1.15],\n",
    "            'DISCO + kNN (ours)': [1.17, 1.29, 1.2, 1.31, 1.59, 1.53, 1.57, 1.56],\n",
    "            'Random + Eval': [14.28, 9.05, 4.62, 3.45, 2.45, 1.4, 0.92, 0.73],\n",
    "            'Random + Random Forest': [3.23, 2.57, 2.05, 1.81, 1.66, 1.59, 1.51, 1.55],\n",
    "            'Anchor-correctness + gp-IRT': [3.4, 2.62, 2.24, 2.08, 1.67, 1.46, 1.14, 0.82]}\n",
    "        num_anchors_axis = [10, 30, 60, 100, 200, 500, 1000, 2000]\n",
    "    else:\n",
    "        for num_anchors, data_for_table_1 in figure_n_anchors_data.items():\n",
    "            assert len(data_for_table_1) >= 2 # mae and rank for mmlu and possibly helm\n",
    "\n",
    "            mmlu_maes, num_anchors_mmlu_maes = data_for_table_1[0]\n",
    "            mmlu_ranks, num_anchors_mmlu_ranks = data_for_table_1[1]\n",
    "            # helm_maes, num_anchors_helm_maes = data_for_table_1[2]\n",
    "            # helm_ranks, num_anchors_helm_ranks = data_for_table_1[3]\n",
    "            assert num_anchors_mmlu_maes == num_anchors_mmlu_ranks == num_anchors\n",
    "\n",
    "            maes[\"DISCO + Random Forest (ours)\"].append(prepare_mae(mmlu_maes.loc[\"highest\"][\"fit\"]))\n",
    "            ranks[\"DISCO + Random Forest (ours)\"].append(prepare_rank(mmlu_ranks.loc[\"highest\"][\"fit\"]))\n",
    "\n",
    "            maes[\"DISCO + kNN (ours)\"].append(prepare_mae(mmlu_maes.loc[\"highest\"][\"KNN\"]))\n",
    "            ranks[\"DISCO + kNN (ours)\"].append(prepare_rank(mmlu_ranks.loc[\"highest\"][\"KNN\"]))\n",
    "\n",
    "            maes[\"Random + Eval\"].append(prepare_mae(mmlu_maes.loc[\"random\"][\"naive\"]))\n",
    "            ranks[\"Random + Eval\"].append(prepare_rank(mmlu_ranks.loc[\"random\"][\"naive\"]))\n",
    "\n",
    "            maes[\"Random + Random Forest\"].append(prepare_mae(mmlu_maes.loc[\"random\"][\"fit\"]))\n",
    "            ranks[\"Random + Random Forest\"].append(prepare_rank(mmlu_ranks.loc[\"random\"][\"fit\"]))\n",
    "\n",
    "            maes[\"Anchor-correctness + gp-IRT\"].append(prepare_mae(mmlu_maes.loc[\"anchor\"][\"gpirt\"]))\n",
    "            ranks[\"Anchor-correctness + gp-IRT\"].append(prepare_rank(mmlu_ranks.loc[\"anchor\"][\"gpirt\"]))\n",
    "            num_anchors_axis.append(num_anchors)\n",
    "    # Create line plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    print(ranks)\n",
    "    print(maes)\n",
    "\n",
    "    for method, mae_values in maes.items():\n",
    "        plt.plot(num_anchors_axis, mae_values, marker='o', label=method)\n",
    "\n",
    "    plt.xlabel('Number of Anchors')\n",
    "    plt.ylabel('Mean Absolute Error (MAE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title('MAE vs Number of Anchors by Method')\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(num_anchors_axis)\n",
    "    plt.yticks(\n",
    "        [1.0, 1.1, 1.3, 1.5, 2.0, 3.0, 10.0],\n",
    "        ['1.0', '1.1', '1.3', '1.5', '2.0', '3.0', '10.0']\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    for method, rank_values in ranks.items():\n",
    "        plt.plot(num_anchors_axis, rank_values, marker='o', label=method)\n",
    "\n",
    "    plt.xlabel('Number of Anchors')\n",
    "    plt.ylabel('Rank Correlation')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title('Rank Correlation vs Number of Anchors by Method')\n",
    "    plt.xticks(num_anchors_axis)\n",
    "    plt.yticks(\n",
    "        [0.60, 0.70, 0.80, 0.90, 0.92, 0.95, 0.98, 1.00],\n",
    "        ['0.60', '0.70', '0.80', '0.90', '0.92', '0.95', '0.98', '1.00']\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "\n",
    "    # Save MAE plot\n",
    "    plt.figure(1)  # Switch to first figure (MAE plot)\n",
    "    plt.savefig(os.path.join(FIGURES_FOLDER, 'num_samples', 'mae_vs_n_anchors.pdf'), bbox_inches='tight')\n",
    "\n",
    "    # Save rank correlation plot\n",
    "    plt.figure(2)  # Switch to second figure (rank plot)\n",
    "    plt.savefig(os.path.join(FIGURES_FOLDER, 'num_samples', 'rank_vs_n_anchors.pdf'), bbox_inches='tight')\n",
    "\n",
    "    return plt.gcf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_n_anchors = make_figure_n_anchors(figure_n_anchors_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_n_anchors = make_figure_n_anchors(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_figure_n_anchors_hard_coded_v2(figure_n_anchors_data):\n",
    "    # Disable matplotlib debug logging\n",
    "    logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "    # logger.debug(\"Starting to create figures\")\n",
    "    maes = {}\n",
    "    ranks = {}\n",
    "    num_anchors_axis = []\n",
    "\n",
    "    # Set global font sizes\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 14,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 14,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'legend.fontsize': 12,\n",
    "    })\n",
    "\n",
    "    # Map methods to their corresponding entries in the data dictionaries\n",
    "    method_mapping = {\n",
    "        \"Random / Direct evaluation\": 'Random Eval',\n",
    "        \"Anchor-corr / gp-IRT (tinyBenchmarks)\": 'Anchor-correctness gp-IRT',\n",
    "        \"Random / Signature-RF\": 'Random Linear',\n",
    "        \"High PDS / Signature-kNN (DISCO)\": 'DISCO-kNN (ours)',\n",
    "        \"High PDS / Signature-RF (DISCO)\": 'DISCO-linear (ours)',\n",
    "    }\n",
    "\n",
    "    # Group the methods\n",
    "    groups = {\n",
    "        \"Random\": [\"Random / Direct evaluation\"],\n",
    "        \"Anchor-corr\": [\"Anchor-corr / gp-IRT (tinyBenchmarks)\"],\n",
    "        \"Our Signature-RF\": [\"Random / Signature-RF\"],\n",
    "        \"DISCO (ours)\": [\"High PDS / Signature-kNN (DISCO)\", \"High PDS / Signature-RF (DISCO)\"]\n",
    "    }\n",
    "\n",
    "    # Define style for each group\n",
    "    group_styles = {\n",
    "        \"Random\": {'colors': ['#999999'], 'markers': ['s'], 'linestyles': ['-'], 'zorder': 1},\n",
    "        \"Anchor-corr\": {'colors': ['#6baed6'], 'markers': ['^'], 'linestyles': ['-'], 'zorder': 2},\n",
    "        \"Our Signature-RF\": {'colors': ['#4daf4a'], 'markers': ['d'], 'linestyles': ['--'], 'zorder': 2, 'linewidth': 1.8},\n",
    "        \"DISCO (ours)\": {'colors': ['#984ea3', '#e41a1c'], 'markers': ['*', 'o'], 'linestyles': ['--', '-'], 'zorder': 3, 'linewidth': 2.5}\n",
    "    }\n",
    "\n",
    "    # Hard-coded data for ranks\n",
    "    # logger.debug(\"Setting up ranks data\")\n",
    "\n",
    "    if figure_n_anchors_data is None:\n",
    "        # ranks = {\n",
    "        #     'DISCO-linear (ours)': [96.24, 98.01, 98.03, 98.58],\n",
    "        #     'DISCO-kNN (ours)': [97.26, 97.54, 97.28, 97.21],\n",
    "        #     'Random Eval': [57.43, 72.08, 86.5, 91.55],\n",
    "        #     'Random Linear': [83.24, 90.38, 91.9, 94.23],\n",
    "        #     'Anchor-correctness gp-IRT': [84.5, 88.15, 92.46, 92.72]\n",
    "        # }\n",
    "\n",
    "        ranks = {'DISCO-linear (ours)': [0.96, 0.977, 0.981, 0.987, 0.977, 0.985, 0.984, 0.979], 'DISCO-kNN (ours)': [0.973, 0.975, 0.973, 0.972, 0.974, 0.957, 0.952, 0.95], 'Random Eval': [0.574, 0.721, 0.865, 0.916, 0.944, 0.972, 0.988, 0.992], 'Random Linear': [0.824, 0.866, 0.901, 0.933, 0.928, 0.932, 0.952, 0.959], 'Anchor-correctness gp-IRT': [0.845, 0.882, 0.925, 0.927, 0.956, 0.974, 0.991, 0.996]}\n",
    "\n",
    "        # Hard-coded data for MAEs\n",
    "        # logger.debug(\"Setting up MAEs data\")\n",
    "        # maes = {\n",
    "        #     'DISCO-linear (ours)': [2.05, 1.22, 1.11, 1.04],\n",
    "        #     'DISCO-kNN (ours)': [1.17, 1.29, 1.2, 1.31],\n",
    "        #     'Random Eval': [14.28, 9.05, 4.62, 3.45],\n",
    "        #     'Random Linear': [3.1, 2.4, 1.9, 1.59],\n",
    "        #     'Anchor-correctness gp-IRT': [3.4, 2.62, 2.24, 2.08]\n",
    "        # }\n",
    "        maes = {'DISCO-linear (ours)': [2.05, 1.2, 1.16, 1.07, 1.08, 1.02, 0.93, 1.15], 'DISCO-kNN (ours)': [1.17, 1.29, 1.2, 1.31, 1.59, 1.53, 1.57, 1.56], 'Random Eval': [14.28, 9.05, 4.62, 3.45, 2.45, 1.4, 0.92, 0.73], 'Random Linear': [3.23, 2.57, 2.05, 1.81, 1.66, 1.59, 1.51, 1.55], 'Anchor-correctness gp-IRT': [3.4, 2.62, 2.24, 2.08, 1.67, 1.46, 1.14, 0.82]}\n",
    "\n",
    "        num_anchors_axis = [10, 30, 60, 100, 200, 500, 1000, 2000]\n",
    "    else:\n",
    "        method_names = [\n",
    "            \"DISCO-linear (ours)\",\n",
    "            \"DISCO-kNN (ours)\",\n",
    "            \"Random Eval\",\n",
    "            \"Random Linear\",\n",
    "            \"Anchor-correctness gp-IRT\"\n",
    "        ]\n",
    "        for method in method_names:\n",
    "            maes[method] = []\n",
    "            ranks[method] = []\n",
    "        for num_anchors, data_for_table_1 in figure_n_anchors_data.items():\n",
    "            assert len(data_for_table_1) >= 2 # mae and rank for mmlu and possibly helm\n",
    "\n",
    "            mmlu_maes, num_anchors_mmlu_maes = data_for_table_1[0]\n",
    "            mmlu_ranks, num_anchors_mmlu_ranks = data_for_table_1[1]\n",
    "            # helm_maes, num_anchors_helm_maes = data_for_table_1[2]\n",
    "            # helm_ranks, num_anchors_helm_ranks = data_for_table_1[3]\n",
    "            assert num_anchors_mmlu_maes == num_anchors_mmlu_ranks == num_anchors\n",
    "\n",
    "            maes[method_names[0]].append(prepare_mae(mmlu_maes.loc[\"highest\"][\"fit\"]))\n",
    "            ranks[method_names[0]].append(prepare_rank(mmlu_ranks.loc[\"highest\"][\"fit\"]))\n",
    "\n",
    "            maes[method_names[1]].append(prepare_mae(mmlu_maes.loc[\"highest\"][\"KNN\"]))\n",
    "            ranks[method_names[1]].append(prepare_rank(mmlu_ranks.loc[\"highest\"][\"KNN\"]))\n",
    "\n",
    "            maes[method_names[2]].append(prepare_mae(mmlu_maes.loc[\"random\"][\"naive\"]))\n",
    "            ranks[method_names[2]].append(prepare_rank(mmlu_ranks.loc[\"random\"][\"naive\"]))\n",
    "\n",
    "            maes[method_names[3]].append(prepare_mae(mmlu_maes.loc[\"random\"][\"fit\"]))\n",
    "            ranks[method_names[3]].append(prepare_rank(mmlu_ranks.loc[\"random\"][\"fit\"]))\n",
    "\n",
    "            maes[method_names[4]].append(prepare_mae(mmlu_maes.loc[\"anchor\"][\"gpirt\"]))\n",
    "            ranks[method_names[4]].append(prepare_rank(mmlu_ranks.loc[\"anchor\"][\"gpirt\"]))\n",
    "            num_anchors_axis.append(num_anchors)\n",
    "    # Generate x-ticks with every 10 samples\n",
    "    # x_ticks = list(range(10, 101, 10))\n",
    "    x_ticks = list(range(10, num_anchors_axis[-1], 10))\n",
    "    print(maes)\n",
    "    print(ranks)\n",
    "    print(num_anchors_axis)\n",
    "\n",
    "    # Function to create plots with grouped styling\n",
    "    def create_styled_plot(plot_data, ylabel, yscale=None, yticks=None, yticklabels=None):\n",
    "        for group_name, methods in groups.items():\n",
    "            style = group_styles[group_name]\n",
    "            for i, method in enumerate(methods):\n",
    "                data_key = method_mapping[method]\n",
    "                if data_key in plot_data:\n",
    "                    linewidth = style.get('linewidth', 1.5)\n",
    "\n",
    "                    # For DISCO methods, make them stand out more\n",
    "                    if group_name == \"DISCO (ours)\":\n",
    "                        # Extract the model type (kNN or RF) from the method name\n",
    "                        model_type = \"kNN\" if \"kNN\" in method else \"RF\"\n",
    "                        # Create label showing High PDS and DISCO\n",
    "                        label = f\"High PDS / Signature-{model_type} (DISCO)\"\n",
    "                        # Bold weights for our methods in the legend\n",
    "                        label = r\"$\\bf{\" + label + \"}$\"\n",
    "                    elif group_name == \"Our Signature-RF\":\n",
    "                        label = r\"$\\bf{Random / Signature-RF}$\"\n",
    "                    else:\n",
    "                        label = method\n",
    "\n",
    "                    plt.plot(\n",
    "                        num_anchors_axis,\n",
    "                        plot_data[data_key],\n",
    "                        marker=style['markers'][i % len(style['markers'])],\n",
    "                        color=style['colors'][i % len(style['colors'])],\n",
    "                        linestyle=style['linestyles'][i % len(style['linestyles'])],\n",
    "                        linewidth=linewidth,\n",
    "                        label=label,\n",
    "                        zorder=style['zorder'],\n",
    "                        markersize=8 if group_name == \"DISCO (ours)\" else 6\n",
    "                    )\n",
    "\n",
    "        plt.xlabel('Number of Samples')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend(frameon=False)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        if yscale:\n",
    "            plt.yscale(yscale)\n",
    "        plt.xticks(x_ticks)\n",
    "        if yticks and yticklabels:\n",
    "            plt.yticks(yticks, yticklabels)\n",
    "        # Set x-axis to log scale\n",
    "        plt.xscale('log')\n",
    "\n",
    "    # Create combined figure for plot.pdf\n",
    "    # logger.debug(\"Creating combined figure\")\n",
    "    plt.figure(figsize=(16, 5))\n",
    "\n",
    "    # First subplot - MAE\n",
    "    plt.subplot(1, 2, 1)\n",
    "    create_styled_plot(\n",
    "        maes,\n",
    "        'Mean Absolute Error (MAE)',\n",
    "        yscale='log',\n",
    "        yticks=[1.0, 2.0, 5.0, 10.0, 20.0],\n",
    "        yticklabels=['1.0', '2.0', '5.0', '10.0', '20.0']\n",
    "    )\n",
    "\n",
    "    # Second subplot - Rank Correlation\n",
    "    plt.subplot(1, 2, 2)\n",
    "    create_styled_plot(\n",
    "        ranks,\n",
    "        'Spearman Rank Correlation',\n",
    "        # yticks=[50, 60, 70, 80, 90, 95, 100],\n",
    "        yticks=[0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 1.00],\n",
    "        yticklabels=['0.50', '0.60', '0.70', '0.80', '0.90', '0.95', '1.00']\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save only the combined plot\n",
    "    # logger.debug(\"Saving combined plot to file\")\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(N_SAMPLES_FIGURE_FOLDER, exist_ok=True)\n",
    "\n",
    "    # Save combined plot\n",
    "    plot_file = os.path.join(N_SAMPLES_FIGURE_FOLDER, 'plot.pdf')\n",
    "    print(f\"Saving combined plot to {plot_file}\")\n",
    "    plt.savefig(plot_file, bbox_inches='tight')\n",
    "    # logger.debug(f\"Saved combined plot to {plot_file}\")\n",
    "\n",
    "    # Apply pdfcrop only to the combined plot\n",
    "    # logger.debug(\"Applying pdfcrop to tighten only the combined plot\")\n",
    "    apply_pdfcrop(plot_file)\n",
    "\n",
    "    return plt.gcf()\n",
    "\n",
    "def apply_pdfcrop(pdf_file):\n",
    "    \"\"\"Apply pdfcrop to tighten the PDF.\"\"\"\n",
    "    try:\n",
    "        # logger.debug(f\"Running pdfcrop on {pdf_file}\")\n",
    "        # subprocess.run([\"pdfcrop\", pdf_file, pdf_file], check=True)\n",
    "        subprocess.run([\"pdfcrop\", pdf_file, pdf_file], check=False)\n",
    "        # logger.debug(f\"Successfully cropped {pdf_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"Error running pdfcrop on {pdf_file}: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"pdfcrop command not found. Make sure it's installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_figure_n_anchors_hard_coded_v2(figure_n_anchors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_figure_n_anchors_hard_coded_v2(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
