{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# import pickle\n",
    "from plots import (\n",
    "    MAX_TABLE_SIZE,\n",
    "    make_table_avg,\n",
    "    make_perf_table,\n",
    ")\n",
    "from utils import load_pickle\n",
    "from generating_data.utils_for_notebooks import merge_methods\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_1(data_for_table_1):\n",
    "\n",
    "    def prepare_mae(mae_value):\n",
    "        if mae_value is None or mae_value == float('nan'):\n",
    "            return float('nan')\n",
    "        else:\n",
    "            return round(mae_value * 100, 2)\n",
    "\n",
    "    def prepare_rank(rank_value):\n",
    "        if rank_value is None or rank_value == float('nan'):\n",
    "            return float('nan')\n",
    "        else:\n",
    "            return round(rank_value * 100, 2)\n",
    "\n",
    "    assert len(data_for_table_1) == 4 # mae and rank for mmlu and helm\n",
    "\n",
    "    rows = []\n",
    "    mmlu_maes, num_anchors_mmlu_maes = data_for_table_1[0]\n",
    "    mmlu_ranks, num_anchors_mmlu_ranks = data_for_table_1[1]\n",
    "    helm_maes, num_anchors_helm_maes = data_for_table_1[2]\n",
    "    helm_ranks, num_anchors_helm_ranks = data_for_table_1[3]\n",
    "    assert num_anchors_mmlu_maes == num_anchors_mmlu_ranks == num_anchors_helm_maes == num_anchors_helm_ranks\n",
    "    num_anchors = num_anchors_mmlu_maes\n",
    "\n",
    "    if helm_maes is None:\n",
    "        helm_maes = mmlu_maes.copy()\n",
    "        helm_maes.loc[:,:] = float('nan')\n",
    "    if helm_ranks is None:\n",
    "        helm_ranks = mmlu_ranks.copy()\n",
    "        helm_ranks.loc[:,:] = float('nan')\n",
    "\n",
    "    rows.append([ # headers\n",
    "        \"Approach\",\n",
    "        \"Condensation\", # type\n",
    "        \"Condensation\", # num_anchors\n",
    "        \"Prediction\", # type\n",
    "        \"MMLU\", # mae\n",
    "        \"MMLU\", # rank\n",
    "        \"HELM\", # mae\n",
    "        \"HELM\", # rank\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"\",\n",
    "        \"type\", # type\n",
    "        \"num_anchors\", # num_anchors\n",
    "        \"type\", # type\n",
    "        \"mae\", # mae\n",
    "        \"rank\", # rank\n",
    "        \"mae\", # mae\n",
    "        \"rank\", # rank\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"Baseline\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"Eval\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"naive\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"naive\"]),\n",
    "        prepare_mae(helm_maes.loc[\"random\"][\"naive\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"random\"][\"naive\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"Baseline\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"kNN\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"KNN\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"KNN\"]),\n",
    "        prepare_mae(helm_maes.loc[\"random\"][\"KNN\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"random\"][\"KNN\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"Baseline\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"linear\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"linear\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"linear\"]),\n",
    "        prepare_mae(helm_maes.loc[\"random\"][\"linear\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"random\"][\"linear\"]),\n",
    "    ])\n",
    "    # tinyBenchmarks\n",
    "    rows.append([\n",
    "        \"tinyBenchmarks\",\n",
    "        \"anchor-correctness\",\n",
    "        num_anchors,\n",
    "        \"gp-IRT\",\n",
    "        prepare_mae(mmlu_maes.loc[\"anchor\"][\"gpirt\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"anchor\"][\"gpirt\"]),\n",
    "        prepare_mae(helm_maes.loc[\"anchor\"][\"gpirt\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"anchor\"][\"gpirt\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"tinyBenchmarks\",\n",
    "        \"anchor-IRT\",\n",
    "        num_anchors,\n",
    "        \"gp-IRT\",\n",
    "        prepare_mae(mmlu_maes.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "        prepare_mae(helm_maes.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"anchor-irt\"][\"gpirt\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"tinyBenchmarks\",\n",
    "        \"Random\",\n",
    "        num_anchors,\n",
    "        \"gp-IRT\",\n",
    "        prepare_mae(mmlu_maes.loc[\"random\"][\"gpirt\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"random\"][\"gpirt\"]),\n",
    "        prepare_mae(helm_maes.loc[\"random\"][\"gpirt\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"random\"][\"gpirt\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"DISCO (ours)\",\n",
    "        \"High PDS\",\n",
    "        num_anchors,\n",
    "        \"kNN\",\n",
    "        prepare_mae(mmlu_maes.loc[\"highest\"][\"KNN\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"highest\"][\"KNN\"]),\n",
    "        prepare_mae(helm_maes.loc[\"highest\"][\"KNN\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"highest\"][\"KNN\"]),\n",
    "    ])\n",
    "    rows.append([\n",
    "        \"DISCO (ours)\",\n",
    "        \"High PDS\",\n",
    "        num_anchors,\n",
    "        \"linear\",\n",
    "        prepare_mae(mmlu_maes.loc[\"highest\"][\"linear\"]),\n",
    "        prepare_rank(mmlu_ranks.loc[\"highest\"][\"linear\"]),\n",
    "        prepare_mae(helm_maes.loc[\"highest\"][\"linear\"]),\n",
    "        prepare_rank(helm_ranks.loc[\"highest\"][\"linear\"]),\n",
    "    ])\n",
    "\n",
    "    # res[\"baseline\"] = {\n",
    "    #     \"mae\": 0.0,\n",
    "    #     \"rank\": 0.0\n",
    "    # }\n",
    "    # res[\"ours\"] = {\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # display(df)\n",
    "\n",
    "    latex_str = make_table_1_latex(df)\n",
    "\n",
    "    return df, latex_str\n",
    "\n",
    "\n",
    "def make_table_1_latex(df):\n",
    "        # Add column headers\n",
    "    df.columns = [\"Approach\", \"Type\", \"# Samples\", \"Type\", \"MAE\", \"Rank\", \"MAE\", \"Rank\"]\n",
    "\n",
    "    # Create LaTeX table content\n",
    "    latex_str = \"\\\\begin{table}[H]\\n\"\n",
    "    latex_str += \"\\\\centering\\n\\\\small\\n\"\n",
    "    latex_str += \"\\\\begin{tabular}{c|cc|c|cc|cc}\\n\"\n",
    "    latex_str += \"\\\\toprule\\n\"\n",
    "    latex_str += \"\\\\multicolumn{1}{c}{\\\\textbf{Approach}}&\\\\multicolumn{2}{c}{\\\\textbf{Condensation}} & \\\\multicolumn{1}{c}{\\\\textbf{Prediction}} & \\\\multicolumn{2}{c}{\\\\textbf{MMLU}}& \\\\multicolumn{2}{c}{\\\\textbf{HELM}} \\\\\\\\\\n\"\n",
    "    latex_str += \"&Type & \\\\# \\\\negthinspace Samples & Type & {MAE}  &Rank& {MAE}  &Rank \\\\\\\\\\n\"\n",
    "    latex_str += \"\\\\toprule\\n\"\n",
    "\n",
    "    # Process each row\n",
    "    current_approach = \"\"\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"Approach\"] == \"Approach\" or row[\"Approach\"] == \"\":\n",
    "            continue\n",
    "        if row[\"Approach\"] == current_approach:\n",
    "            approach_str = \"\"\n",
    "        else:\n",
    "            approach_str = row[\"Approach\"]\n",
    "            current_approach = row[\"Approach\"]\n",
    "\n",
    "            # Add midrule before new approach except for first one\n",
    "            if approach_str != \"Baseline\":\n",
    "                latex_str += \"\\\\midrule\\n\"\n",
    "\n",
    "        # Format numbers\n",
    "        mae_mmlu = \"-\" if pd.isna(row[\"MAE\"].values[0]) else f\"{float(row['MAE'].values[0]):.2f}\"\n",
    "        rank_mmlu = \"-\" if pd.isna(row[\"Rank\"].values[0]) else f\"{float(row['Rank'].values[0]):.2f}\"\n",
    "        mae_helm = \"-\" if pd.isna(row[\"MAE\"].values[1]) else f\"{float(row['MAE'].values[1]):.2f}\"\n",
    "        rank_helm = \"-\" if pd.isna(row[\"Rank\"].values[1]) else f\"{float(row['Rank'].values[1]):.2f}\"\n",
    "\n",
    "        # Bold best results\n",
    "        if approach_str == \"DISCO (ours)\" and row[\"Type\"].values[1] == \"linear\":\n",
    "            mae_mmlu = f\"\\\\textbf{{{mae_mmlu}}}\"\n",
    "            rank_mmlu = f\"\\\\textbf{{{rank_mmlu}}}\"\n",
    "\n",
    "        latex_str += f\"{approach_str}&{row['Type'].values[0]} & {row['# Samples']} & {row['Type'].values[1]} & {mae_mmlu} &{rank_mmlu} & {mae_helm} &{rank_helm} \\\\\\\\\\n\"\n",
    "\n",
    "    latex_str += \"\\\\bottomrule\\n\"\n",
    "    latex_str += \"\\\\end{tabular}\\n\"\n",
    "    latex_str += \"\\\\vspace{1em}\\n\"\n",
    "    latex_str += \"\\\\caption{Mean Absolute Error (MAE) for different sampling and prediction strategies. For question answering task on MMLU dataset [FIX]. \\\\joon{Add computational complexity info\\nAdd HELM results, add ranking metric, add method from HELM.\\n}}\\n\"\n",
    "    latex_str += \"\\\\label{tab:language-main}\\n\"\n",
    "    latex_str += \"\\\\end{table}\"\n",
    "\n",
    "    # Store LaTeX code in DataFrame metadata\n",
    "    df.attrs['latex_table'] = latex_str\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "def extract_data_for_table_1(source_df, num_anchors, lower_better):\n",
    "    # Group by PDS type and calculate mean for each group\n",
    "    df = source_df[num_anchors]\n",
    "    # display(df)\n",
    "\n",
    "    # Keep rows with NaN PDS type and group the rest\n",
    "    nan_rows = df[df['PDS type'].isna()]\n",
    "    non_nan_rows = df[df['PDS type'].notna()]\n",
    "    if lower_better:\n",
    "        grouped_non_nan = non_nan_rows.groupby('PDS type').min()\n",
    "    else:\n",
    "        grouped_non_nan = non_nan_rows.groupby('PDS type').max()\n",
    "    grouped_df = pd.concat([grouped_non_nan, nan_rows])\n",
    "\n",
    "    # Get the columns to find minimum across\n",
    "    min_cols = ['MLP3_e700_lr0.001', 'Ridge_10', 'Lasso_e-4', 'RandomForestRegressor_100', 'GradientBoostingRegressor_200']\n",
    "\n",
    "    # Find minimum value across specified columns and store in new 'linear' column\n",
    "    if lower_better:\n",
    "        grouped_df['linear'] = grouped_df[min_cols].min(axis=1)\n",
    "    else:\n",
    "        grouped_df['linear'] = grouped_df[min_cols].max(axis=1)\n",
    "\n",
    "    # Drop the original columns\n",
    "    grouped_df = grouped_df.drop(columns=min_cols)\n",
    "\n",
    "\n",
    "    # display(grouped_df)\n",
    "    # sys.exit(0)\n",
    "\n",
    "    # Drop the stratified and #guiding_models columns since they're no longer meaningful after grouping\n",
    "    for cols_to_drop in ['stratified', '#guiding_models', 'cirt', 'pirt']:\n",
    "        if cols_to_drop in grouped_df.columns:\n",
    "            grouped_df = grouped_df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    return grouped_df, num_anchors\n",
    "\n",
    "\n",
    "def make_df_with_results(table_avg, table_std, bench, split):\n",
    "    cur_methods_for_table = table_avg[\"mmlu_fields\"][split].keys()\n",
    "\n",
    "    df = make_perf_table(\n",
    "        table_avg[bench][split],\n",
    "        table_std[bench][split],\n",
    "        methods=cur_methods_for_table,\n",
    "    )\n",
    "\n",
    "    pd.set_option('display.max_rows', MAX_TABLE_SIZE)\n",
    "    pd.set_option('display.max_columns', MAX_TABLE_SIZE)\n",
    "    pd.set_option(\n",
    "        \"display.max_colwidth\", MAX_TABLE_SIZE\n",
    "    )\n",
    "    for num_samples in df.keys():\n",
    "        # print(\"#anchor_points:\", num_samples)\n",
    "        # Reorder columns to put guiding models, PDS type, and stratified first\n",
    "        cols = df[num_samples].columns.tolist()\n",
    "        first_cols = ['#guiding_models', 'PDS type', 'stratified']\n",
    "        other_cols = [col for col in cols if col not in first_cols]\n",
    "        df[num_samples] = df[num_samples][first_cols + other_cols]\n",
    "\n",
    "        # Replace all values in #guiding_models column with 382\n",
    "        df[num_samples].loc[df[num_samples]['#guiding_models'] == 'all', '#guiding_models'] = 382\n",
    "\n",
    "        # Sort rows by #guiding_models\n",
    "        df[num_samples] = df[num_samples].sort_values(['PDS type', 'stratified', '#guiding_models'])\n",
    "\n",
    "        # print(df[num_samples])\n",
    "\n",
    "    # df[max(list(df.keys()))].to_csv(results_table_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/weka/oh/arubinstein17/github/efficbench/plots.py:445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n",
      "/weka/oh/arubinstein17/github/efficbench/plots.py:445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rank_corrs[i,j,l] = stats.spearmanr(data.mean(axis=3)[i,j,:,l], scores.T.mean(axis=1)).statistic\n"
     ]
    }
   ],
   "source": [
    "# load needed results\n",
    "# benches = [\n",
    "#     \"mmlu_fields\",\n",
    "#     # \"helm\"\n",
    "# ]\n",
    "# splits = [\n",
    "#     # \"iid\",\n",
    "#     \"noniid\"\n",
    "# ]\n",
    "results_suffixes = {\n",
    "    \"mmlu_fields\": {\n",
    "\n",
    "        \"iid\": {\n",
    "            \"ours\": \"_disagreement_best_47\",\n",
    "            \"irt\": \"_disagreement_compare_with_irt43\"\n",
    "        },\n",
    "        \"noniid\": {\n",
    "            \"ours\": \"_disagreement_best_48\",\n",
    "            \"irt\": \"_disagreement_compare_with_irt44\"\n",
    "        }\n",
    "    }\n",
    "    # \"helm\": {\n",
    "    #     \"ours\": {\n",
    "    #         \"filename_suffix\",\n",
    "    #         \"filename_suffix_mmlu_fields\"\n",
    "    #     },\n",
    "    # }\n",
    "}\n",
    "scenarios_to_skip = []\n",
    "table_1_data = []\n",
    "for bench, per_bench in results_suffixes.items():\n",
    "    ordered = bench == \"mmlu_fields\"\n",
    "    for split, per_split in per_bench.items():\n",
    "        for agg_type in [\"mae\", \"rank\"]:\n",
    "            table_avg_base = None\n",
    "            table_std_base = None\n",
    "            for method in [\n",
    "                \"ours\",\n",
    "                \"irt\"\n",
    "            ]:\n",
    "                # our_results_path = f'results/accs_{bench}_split-{split}_iterations-5{per_split[\"ours\"]}.pickle'\n",
    "\n",
    "                # data_ours = load_pickle(our_results_path)\n",
    "                # irt_results_path = f'results/accs_{bench}_split-{split}_iterations-5{per_split[\"irt\"]}.pickle'\n",
    "\n",
    "                # data_irt = load_pickle(irt_results_path)\n",
    "                filename_suffix = per_split[method]\n",
    "                results_path = f'results/accs_{bench}_split-{split}_iterations-5{filename_suffix}.pickle'\n",
    "                data = load_pickle(results_path)\n",
    "\n",
    "                current_table_avg, current_table_std, current_model_perf = make_table_avg(\n",
    "                    bench,\n",
    "                    split,\n",
    "                    filename_suffix,\n",
    "                    data,\n",
    "                    scenarios_to_skip=scenarios_to_skip,\n",
    "                    ordered=ordered,\n",
    "                    return_perf_table=True,\n",
    "                    agg_type=agg_type\n",
    "                )\n",
    "                table_avg_base = merge_methods(table_avg_base, current_table_avg)\n",
    "                table_std_base = merge_methods(table_std_base, current_table_std)\n",
    "            if split == \"noniid\":\n",
    "                df = make_df_with_results(table_avg_base, table_std_base, bench, split)\n",
    "                table_1_data.append(extract_data_for_table_1(df, num_anchors=100, lower_better=(agg_type == \"mae\")))\n",
    "                # print(\"DEBUG\", df[100])\n",
    "\n",
    "# generate table_avg, perf_avg and etc\n",
    "# extract max across sampling methods\n",
    "# for table in table_1_data:\n",
    "#     print(\"DEBUG\")\n",
    "#     display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Type</th>\n",
       "      <th># Samples</th>\n",
       "      <th>Type</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Rank</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approach</td>\n",
       "      <td>Condensation</td>\n",
       "      <td>Condensation</td>\n",
       "      <td>Prediction</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>HELM</td>\n",
       "      <td>HELM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>type</td>\n",
       "      <td>num_anchors</td>\n",
       "      <td>type</td>\n",
       "      <td>mae</td>\n",
       "      <td>rank</td>\n",
       "      <td>mae</td>\n",
       "      <td>rank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random</td>\n",
       "      <td>100</td>\n",
       "      <td>Eval</td>\n",
       "      <td>3.45</td>\n",
       "      <td>91.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random</td>\n",
       "      <td>100</td>\n",
       "      <td>kNN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>91.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.59</td>\n",
       "      <td>94.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tinyBenchmarks</td>\n",
       "      <td>anchor-correctness</td>\n",
       "      <td>100</td>\n",
       "      <td>gp-IRT</td>\n",
       "      <td>2.08</td>\n",
       "      <td>92.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tinyBenchmarks</td>\n",
       "      <td>anchor-IRT</td>\n",
       "      <td>100</td>\n",
       "      <td>gp-IRT</td>\n",
       "      <td>3.25</td>\n",
       "      <td>92.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tinyBenchmarks</td>\n",
       "      <td>Random</td>\n",
       "      <td>100</td>\n",
       "      <td>gp-IRT</td>\n",
       "      <td>2.79</td>\n",
       "      <td>92.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DISCO (ours)</td>\n",
       "      <td>High PDS</td>\n",
       "      <td>100</td>\n",
       "      <td>kNN</td>\n",
       "      <td>1.31</td>\n",
       "      <td>97.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DISCO (ours)</td>\n",
       "      <td>High PDS</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.04</td>\n",
       "      <td>98.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Approach                Type     # Samples        Type   MAE   Rank  \\\n",
       "0        Approach        Condensation  Condensation  Prediction  MMLU   MMLU   \n",
       "1                                type   num_anchors        type   mae   rank   \n",
       "2        Baseline              Random           100        Eval  3.45  91.55   \n",
       "3        Baseline              Random           100         kNN  1.82  91.17   \n",
       "4        Baseline              Random           100      linear  1.59  94.23   \n",
       "5  tinyBenchmarks  anchor-correctness           100      gp-IRT  2.08  92.72   \n",
       "6  tinyBenchmarks          anchor-IRT           100      gp-IRT  3.25  92.18   \n",
       "7  tinyBenchmarks              Random           100      gp-IRT  2.79   92.2   \n",
       "8    DISCO (ours)            High PDS           100         kNN  1.31  97.21   \n",
       "9    DISCO (ours)            High PDS           100      linear  1.04  98.58   \n",
       "\n",
       "    MAE  Rank  \n",
       "0  HELM  HELM  \n",
       "1   mae  rank  \n",
       "2   NaN   NaN  \n",
       "3   NaN   NaN  \n",
       "4   NaN   NaN  \n",
       "5   NaN   NaN  \n",
       "6   NaN   NaN  \n",
       "7   NaN   NaN  \n",
       "8   NaN   NaN  \n",
       "9   NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\small\n",
      "\\begin{tabular}{c|cc|c|cc|cc}\n",
      "\\toprule\n",
      "\\multicolumn{1}{c}{\\textbf{Approach}}&\\multicolumn{2}{c}{\\textbf{Condensation}} & \\multicolumn{1}{c}{\\textbf{Prediction}} & \\multicolumn{2}{c}{\\textbf{MMLU}}& \\multicolumn{2}{c}{\\textbf{HELM}} \\\\\n",
      "&Type & \\# \\negthinspace Samples & Type & {MAE}  &Rank& {MAE}  &Rank \\\\\n",
      "\\toprule\n",
      "Baseline&Random & 100 & Eval & 3.45 &91.55 & - &- \\\\\n",
      "&Random & 100 & kNN & 1.82 &91.17 & - &- \\\\\n",
      "&Random & 100 & linear & 1.59 &94.23 & - &- \\\\\n",
      "\\midrule\n",
      "tinyBenchmarks&anchor-correctness & 100 & gp-IRT & 2.08 &92.72 & - &- \\\\\n",
      "&anchor-IRT & 100 & gp-IRT & 3.25 &92.18 & - &- \\\\\n",
      "&Random & 100 & gp-IRT & 2.79 &92.20 & - &- \\\\\n",
      "\\midrule\n",
      "DISCO (ours)&High PDS & 100 & kNN & 1.31 &97.21 & - &- \\\\\n",
      "&High PDS & 100 & linear & 1.04 &98.58 & - &- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\vspace{1em}\n",
      "\\caption{Mean Absolute Error (MAE) for different sampling and prediction strategies. For question answering task on MMLU dataset [FIX]. \\joon{Add computational complexity info\n",
      "Add HELM results, add ranking metric, add method from HELM.\n",
      "}}\n",
      "\\label{tab:language-main}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "table_1, latex_str = make_table_1(table_1_data + [(None, 100), (None, 100)])\n",
    "display(table_1)\n",
    "print(latex_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
