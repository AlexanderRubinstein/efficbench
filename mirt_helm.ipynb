{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952aeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "from experiments import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491d564",
   "metadata": {},
   "source": [
    "Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad64dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {'cnn':['summarization_cnndm:temperature=0.3,device=cuda,'], \n",
    "             'xsum':['summarization_xsum:temperature=0.3,device=cuda,'], \n",
    "             'boolq:':['boolq:'],\n",
    "             'civil_comments':['civil_comments:demographic=LGBTQ,',\n",
    "                               'civil_comments:demographic=all,',\n",
    "                               'civil_comments:demographic=black,',\n",
    "                               'civil_comments:demographic=christian,',\n",
    "                               'civil_comments:demographic=female,',\n",
    "                               'civil_comments:demographic=male,',\n",
    "                               'civil_comments:demographic=muslim,',\n",
    "                               'civil_comments:demographic=other_religions,',\n",
    "                               'civil_comments:demographic=white,'],\n",
    "             'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,':['commonsense:dataset=hellaswag,method=multiple_choice_separate_original,'],\n",
    "             'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,':['commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,'],\n",
    "             'imdb:':['imdb:'],\n",
    "             'mmlu':['mmlu:subject=abstract_algebra,method=multiple_choice_joint,',\n",
    "                     'mmlu:subject=college_chemistry,method=multiple_choice_joint,',\n",
    "                     'mmlu:subject=computer_security,method=multiple_choice_joint,',\n",
    "                     'mmlu:subject=econometrics,method=multiple_choice_joint,',\n",
    "                     'mmlu:subject=us_foreign_policy,method=multiple_choice_joint,'],\n",
    "             'msmarco:track=regular,valid_topk=30,':['msmarco:track=regular,valid_topk=30,'],\n",
    "             #'msmarco:track=trec,valid_topk=30,':['msmarco:track=trec,valid_topk=30,'],\n",
    "             'narrative_qa:':['narrative_qa:'],\n",
    "             'natural_qa:mode=closedbook,':['natural_qa:mode=closedbook,'],\n",
    "             'natural_qa:mode=openbook_longans,':['natural_qa:mode=openbook_longans,'],\n",
    "             'quac:':['quac:'],\n",
    "             'raft':['raft:subset=ade_corpus_v2,',\n",
    "                     'raft:subset=banking_77,',\n",
    "                     'raft:subset=neurips_impact_statement_risks,',\n",
    "                     'raft:subset=one_stop_english,',\n",
    "                     'raft:subset=overruling,',\n",
    "                     'raft:subset=semiconductor_org_types,',\n",
    "                     'raft:subset=systematic_review_inclusion,',\n",
    "                     'raft:subset=tai_safety_research,',\n",
    "                     'raft:subset=terms_of_service,',\n",
    "                     'raft:subset=tweet_eval_hate,',\n",
    "                     'raft:subset=twitter_complaints,'],\n",
    "             'truthful_qa:task=mc_single,method=multiple_choice_joint,':['truthful_qa:task=mc_single,method=multiple_choice_joint,']}\n",
    "            \n",
    "scenarios_metrics = {'boolq:':'em', \n",
    "                     'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,':'em',\n",
    "                     'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,':'em',\n",
    "                     'imdb:':'em', \n",
    "                     'mmlu':'em', \n",
    "                     'msmarco:track=regular,valid_topk=30,':'RR@10', \n",
    "                     'msmarco:track=trec,valid_topk=30,':'NDCG@10', \n",
    "                     'narrative_qa:':'f1', \n",
    "                     'natural_qa:mode=closedbook,':'f1', \n",
    "                     'natural_qa:mode=openbook_longans,':'f1', \n",
    "                     'quac:':'f1', \n",
    "                     'raft':'em', \n",
    "                     'truthful_qa:task=mc_single,method=multiple_choice_joint,':'em'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14725d5d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e324e4",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b24d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/helm.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797477e3",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ca743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3],\n",
       " [5, 6, 7, 8, 9, 10, 11],\n",
       " [4, 12, 13],\n",
       " [14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
       " [23, 24, 25, 26, 27]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "iterations = 3\n",
    "Ds = [5, 10, 15] #\n",
    "\n",
    "set_of_rows = [[0,1,2,3], #ai21\n",
    "               [5,6,7,8,9,10,11], #cohere\n",
    "               [4,12,13], #anthropic+microsoft\n",
    "               [14,15,16,17,18,19,20,21,22], #openai\n",
    "               [23,24,25,26,27]] #together\n",
    "set_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc3c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai21_j1-grande',\n",
       " 'ai21_j1-grande-v2-beta',\n",
       " 'ai21_j1-jumbo',\n",
       " 'ai21_j1-large',\n",
       " 'anthropic_stanford-online-all-v4-s3',\n",
       " 'cohere_command-medium-beta',\n",
       " 'cohere_command-xlarge-beta',\n",
       " 'cohere_large-20220720',\n",
       " 'cohere_medium-20220720',\n",
       " 'cohere_medium-20221108',\n",
       " 'cohere_xlarge-20220609',\n",
       " 'cohere_xlarge-20221108',\n",
       " 'microsoft_TNLGv2_530B',\n",
       " 'microsoft_TNLGv2_7B',\n",
       " 'openai_ada',\n",
       " 'openai_babbage',\n",
       " 'openai_curie',\n",
       " 'openai_davinci',\n",
       " 'openai_text-ada-001',\n",
       " 'openai_text-babbage-001',\n",
       " 'openai_text-curie-001',\n",
       " 'openai_text-davinci-002',\n",
       " 'openai_text-davinci-003',\n",
       " 'together_bloom',\n",
       " 'together_gpt-j-6b',\n",
       " 'together_gpt-neox-20b',\n",
       " 'together_opt-175b',\n",
       " 'together_opt-66b']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['models']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c6fd5",
   "metadata": {},
   "source": [
    "### Predicting accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451897a",
   "metadata": {},
   "source": [
    "Full (one IRT model for all scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models [0, 1, 2, 3]\n",
      "\n",
      "i) choosing optimal D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [11:49<00:00, 236.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- opt D= 5 errors= [0.044579911983804656, 0.0453168327810513, 0.047692893828327226] \n",
      "\n",
      "\n",
      "ii) choosing optimal lambdas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15/15 [00:00<00:00, 54424.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_gpirt': {'cnn': {10: 0.5810980065561022, 25: 0.776185364418146, 50: 0.8739913974827889, 75: 0.9123110788518177, 100: 0.9327592417518723}, 'xsum': {10: 0.12214799049569504, 25: 0.2580834196106841, 50: 0.4102802971372891, 75: 0.5106629684828556, 100: 0.5818422025325208}, 'boolq:': {10: 0.10161491521841513, 25: 0.22043765726512518, 50: 0.36124361773481034, 75: 0.45896613338189834, 100: 0.5307552785238266}, 'civil_comments': {10: 0.03457890877432671, 25: 0.0821844966189413, 50: 0.15188629457492606, 75: 0.2117485876802738, 100: 0.26371751324808634}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.21291920659048225, 25: 0.40344593416830005, 50: 0.5749361971786783, 75: 0.6698451765235517, 100: 0.7301072871505678}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.03920765730939187, 25: 0.09257468829234465, 50: 0.1694615284142004, 75: 0.23433675987525454, 100: 0.28981120677649247}, 'imdb:': {10: 0.2857569388647762, 25: 0.5000522477693923, 50: 0.6667131075107283, 75: 0.7500391837797792, 100: 0.8000334364760335}, 'mmlu': {10: 0.019022837770395193, 25: 0.0462377350275389, 50: 0.08838858221133045, 75: 0.1269714596663881, 100: 0.1624210023073693}, 'msmarco:track=regular,valid_topk=30,': {10: 0.3632696819286022, 25: 0.5878513470339957, 50: 0.7404362481816251, 75: 0.8105675678530346, 100: 0.8508628212670459}, 'narrative_qa:': {10: 0.22445863192952886, 25: 0.4198037251011395, 50: 0.5913545903272438, 75: 0.6846086512450993, 100: 0.7432090797634718}, 'natural_qa:mode=closedbook,': {10: 0.0789085059655423, 25: 0.17639291306459975, 50: 0.29988775196729434, 75: 0.39117702815379685, 100: 0.46140561215910214}, 'natural_qa:mode=openbook_longans,': {10: 0.04196130844748008, 25: 0.09869143829365211, 50: 0.1796526938390038, 75: 0.24726787117985716, 100: 0.30458573913708603}, 'quac:': {10: 0.040670771695173503, 25: 0.09583066838500984, 50: 0.1749005045209058, 75: 0.24125311133637378, 100: 0.2977281971501506}, 'raft': {10: 0.04170566393429632, 25: 0.09812557166303211, 50: 0.1787146646888989, 75: 0.2460827031442657, 100: 0.30323651693273457}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.30722510849470286, 25: 0.5257687358601303, 50: 0.6891853575223975, 75: 0.768841042058951, 100: 0.815997314271367}}, 'anchor_gpirt': {'cnn': {10: 0.847299636699333, 25: 0.9327592417518723, 50: 0.9652099667689701, 75: 0.976534522937046, 100: 0.9822970401029317}, 'xsum': {10: 0.3575645779687924, 25: 0.5818422025325208, 50: 0.7356513836854202, 75: 0.806738082278266, 100: 0.8476948661468692}, 'boolq:': {10: 0.3115004005089903, 25: 0.5307552785238266, 50: 0.6934554281408808, 75: 0.7723782107872434, 100: 0.8189827929539003}, 'civil_comments': {10: 0.12531578572917065, 25: 0.26371751324808634, 50: 0.41736782229164965, 75: 0.5179615014846862, 100: 0.588933677945129}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.5197088428981402, 25: 0.7301072871505678, 50: 0.8440023258361411, 75: 0.8902970839744336, 100: 0.9154026695204283}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.14032516615777493, 25: 0.28981120677649247, 50: 0.4493854685924016, 75: 0.5504059785869291, 100: 0.6201048352290034}, 'imdb:': {10: 0.6154340795356227, 25: 0.8000334364760335, 50: 0.8889095283055154, 75: 0.9230917613680728, 100: 0.9411880399617971}, 'mmlu': {10: 0.0719833673251987, 25: 0.1624210023073693, 50: 0.279452972692284, 75: 0.3677895214862266, 100: 0.4368319565575687}, 'msmarco:track=regular,valid_topk=30,': {10: 0.695316507814246, 25: 0.8508628212670459, 50: 0.9194228891415847, 75: 0.9447992881345753, 100: 0.9580201365138188}, 'narrative_qa:': {10: 0.5365408513279717, 25: 0.7432090797634718, 50: 0.8526906937225389, 75: 0.896722552780348, 100: 0.9204889910784416}, 'natural_qa:mode=closedbook,': {10: 0.2552175234477145, 25: 0.46140561215910214, 50: 0.6314545507696727, 75: 0.7198922176918985, 100: 0.7741000820056811}, 'natural_qa:mode=openbook_longans,': {10: 0.14907863058695842, 25: 0.30458573913708603, 50: 0.4669462956701539, 75: 0.5678432844156908, 100: 0.6366235724489642}, 'quac:': {10: 0.14499224704881625, 25: 0.2977281971501506, 50: 0.4588452309258141, 75: 0.5598301493173459, 100: 0.6290526523291592}, 'raft': {10: 0.14827138595593373, 25: 0.30323651693273457, 50: 0.4653591470049114, 75: 0.5662775108084295, 100: 0.6351468825319335}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.6394943087845636, 25: 0.815997314271367, 50: 0.8986767853219758, 75: 0.9300900223225339, 100: 0.9466348272326709}}, 'anchor-irt_gpirt': {'cnn': {10: 0.847299636699333, 25: 0.9327592417518723, 50: 0.9652099667689701, 75: 0.976534522937046, 100: 0.9822970401029317}, 'xsum': {10: 0.3575645779687924, 25: 0.5818422025325208, 50: 0.7356513836854202, 75: 0.806738082278266, 100: 0.8476948661468692}, 'boolq:': {10: 0.3115004005089903, 25: 0.5307552785238266, 50: 0.6934554281408808, 75: 0.7723782107872434, 100: 0.8189827929539003}, 'civil_comments': {10: 0.12531578572917065, 25: 0.26371751324808634, 50: 0.41736782229164965, 75: 0.5179615014846862, 100: 0.588933677945129}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.5197088428981402, 25: 0.7301072871505678, 50: 0.8440023258361411, 75: 0.8902970839744336, 100: 0.9154026695204283}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.14032516615777493, 25: 0.28981120677649247, 50: 0.4493854685924016, 75: 0.5504059785869291, 100: 0.6201048352290034}, 'imdb:': {10: 0.6154340795356227, 25: 0.8000334364760335, 50: 0.8889095283055154, 75: 0.9230917613680728, 100: 0.9411880399617971}, 'mmlu': {10: 0.0719833673251987, 25: 0.1624210023073693, 50: 0.279452972692284, 75: 0.3677895214862266, 100: 0.4368319565575687}, 'msmarco:track=regular,valid_topk=30,': {10: 0.695316507814246, 25: 0.8508628212670459, 50: 0.9194228891415847, 75: 0.9447992881345753, 100: 0.9580201365138188}, 'narrative_qa:': {10: 0.5365408513279717, 25: 0.7432090797634718, 50: 0.8526906937225389, 75: 0.896722552780348, 100: 0.9204889910784416}, 'natural_qa:mode=closedbook,': {10: 0.2552175234477145, 25: 0.46140561215910214, 50: 0.6314545507696727, 75: 0.7198922176918985, 100: 0.7741000820056811}, 'natural_qa:mode=openbook_longans,': {10: 0.14907863058695842, 25: 0.30458573913708603, 50: 0.4669462956701539, 75: 0.5678432844156908, 100: 0.6366235724489642}, 'quac:': {10: 0.14499224704881625, 25: 0.2977281971501506, 50: 0.4588452309258141, 75: 0.5598301493173459, 100: 0.6290526523291592}, 'raft': {10: 0.14827138595593373, 25: 0.30323651693273457, 50: 0.4653591470049114, 75: 0.5662775108084295, 100: 0.6351468825319335}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.6394943087845636, 25: 0.815997314271367, 50: 0.8986767853219758, 75: 0.9300900223225339, 100: 0.9466348272326709}}}\n",
      "\n",
      "iii) running anchor points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [21:58<00:00, 263.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iv) running random eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [11:00<00:00, 132.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v) running anchor points with IRT embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [20:34<00:00, 246.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models [5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "i) choosing optimal D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [07:42<00:00, 154.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- opt D= 5 errors= [0.05381872300941188, 0.05182277303935221, 0.0543264667069326] \n",
      "\n",
      "\n",
      "ii) choosing optimal lambdas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15/15 [00:00<00:00, 68237.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_gpirt': {'cnn': {10: 0.6800790037019013, 25: 0.8416325599618499, 50: 0.9140070372987809, 75: 0.940979577879858, 100: 0.9550717625246664}, 'xsum': {10: 0.14586503589811217, 25: 0.29919865575231325, 50: 0.46058954021786525, 75: 0.561559983113336, 100: 0.6306899064184214}, 'boolq:': {10: 0.1425382279775365, 25: 0.2935767132258238, 50: 0.4538991931815538, 75: 0.5549117842038082, 100: 0.6243888094996332}, 'civil_comments': {10: 0.03905972098434126, 25: 0.09224472276087652, 50: 0.1689085254222309, 75: 0.23363160332824376, 100: 0.2890021276236617}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.19321110116989337, 25: 0.3744933454437555, 50: 0.5449183827410241, 75: 0.6423605406403432, 100: 0.705433230426347}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.022525857650832985, 25: 0.05447403266873823, 50: 0.10331981818626952, 75: 0.1473667731738924, 100: 0.18728897366516153}, 'imdb:': {10: 0.2761478371514502, 25: 0.4881621924445972, 50: 0.656060468305132, 75: 0.7410152850064138, 100: 0.792314629642197}, 'mmlu': {10: 0.20526020122608044, 25: 0.3923498036063288, 50: 0.5635793571272141, 75: 0.6595224238645411, 100: 0.7208835989785465}, 'msmarco:track=regular,valid_topk=30,': {10: 0.3632790583889827, 25: 0.5878611683953123, 50: 0.7404440389324504, 75: 0.8105737921445311, 100: 0.8508679651505742}, 'narrative_qa:': {10: 0.4535075994702591, 25: 0.6747575104753449, 50: 0.8057972646844009, 75: 0.8615703723430329, 100: 0.8924559588644965}, 'natural_qa:mode=closedbook,': {10: 0.0694046180837822, 25: 0.1571510339683847, 50: 0.27161715170308237, 75: 0.35870985324192267, 100: 0.42719957235446904}, 'natural_qa:mode=openbook_longans,': {10: 0.02588830805935935, 25: 0.06230145139886003, 50: 0.11729523915611753, 75: 0.16619586676471365, 100: 0.20996283711852115}, 'quac:': {10: 0.04627011960461693, 25: 0.10816788738174427, 50: 0.19521931399277648, 75: 0.26678789597250085, 100: 0.32666693335237773}, 'raft': {10: 0.04809281279762815, 25: 0.11214218250889386, 50: 0.20166878708963465, 75: 0.27479444901821776, 100: 0.33564787444977023}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.4842557270968305, 25: 0.701257428709452, 50: 0.8243989614686535, 75: 0.8756542252514949, 100: 0.9037485537757671}}, 'anchor_gpirt': {'cnn': {10: 0.8947710342550738, 25: 0.9550717625246664, 50: 0.9770196479042204, 75: 0.9845615045826402, 100: 0.9883762651928419}, 'xsum': {10: 0.40585846492495486, 25: 0.6306899064184214, 50: 0.7735252471190456, 75: 0.836688162030469, 100: 0.8723024928746601}, 'boolq:': {10: 0.39937450793064283, 25: 0.6243888094996332, 50: 0.7687676815404386, 75: 0.8329709494940996, 100: 0.8692692540276524}, 'civil_comments': {10: 0.1398512334623043, 25: 0.2890021276236617, 50: 0.44841218091152607, 75: 0.5494322211032933, 100: 0.6191775888398395}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.48925557783723783, 25: 0.705433230426347, 50: 0.8272774540109007, 75: 0.8778170527663866, 100: 0.9054754681014803}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.08439989082399077, 25: 0.18728897366516153, 50: 0.3154901255201594, 75: 0.4087559545726242, 100: 0.4796541143103011}, 'imdb:': {10: 0.6041156544821036, 25: 0.792314629642197, 50: 0.8841244907992167, 75: 0.919645972585134, 100: 0.9384990165105116}, 'mmlu': {10: 0.5081387925039232, 25: 0.7208835989785465, 50: 0.83780634484103, 75: 0.8856908221000853, 100: 0.9117460576767137}, 'msmarco:track=regular,valid_topk=30,': {10: 0.6953250955734614, 25: 0.8508679651505742, 50: 0.919425892253047, 75: 0.9448014022477752, 100: 0.9580217667834137}, 'narrative_qa:': {10: 0.7684867094282389, 25: 0.8924559588644965, 50: 0.9431722357227104, 75: 0.9613833240287174, 100: 0.9707551583783545}, 'natural_qa:mode=closedbook,': {10: 0.22977593855447995, 25: 0.42719957235446904, 50: 0.5986542886216152, 75: 0.6911126553957527, 100: 0.7489477779936828}, 'natural_qa:mode=openbook_longans,': {10: 0.09609038014892819, 25: 0.20996283711852115, 50: 0.34705667096113363, 75: 0.44360667800025283, 100: 0.5152814702495129}, 'quac:': {10: 0.16252089470914344, 25: 0.32666693335237773, 50: 0.49246261460201984, 75: 0.5927422281685694, 100: 0.6599329320330612}, 'raft': {10: 0.16811577037202072, 25: 0.33564787444977023, 50: 0.5025993465351678, 75: 0.6024927808332723, 100: 0.6689731999339781}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.7897296258539234, 25: 0.9037485537757671, 50: 0.949441092925148, 75: 0.9657162794699456, 100: 0.9740649218597376}}, 'anchor-irt_gpirt': {'cnn': {10: 0.8947710342550738, 25: 0.9550717625246664, 50: 0.9770196479042204, 75: 0.9845615045826402, 100: 0.9883762651928419}, 'xsum': {10: 0.40585846492495486, 25: 0.6306899064184214, 50: 0.7735252471190456, 75: 0.836688162030469, 100: 0.8723024928746601}, 'boolq:': {10: 0.39937450793064283, 25: 0.6243888094996332, 50: 0.7687676815404386, 75: 0.8329709494940996, 100: 0.8692692540276524}, 'civil_comments': {10: 0.1398512334623043, 25: 0.2890021276236617, 50: 0.44841218091152607, 75: 0.5494322211032933, 100: 0.6191775888398395}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.48925557783723783, 25: 0.705433230426347, 50: 0.8272774540109007, 75: 0.8778170527663866, 100: 0.9054754681014803}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.08439989082399077, 25: 0.18728897366516153, 50: 0.3154901255201594, 75: 0.4087559545726242, 100: 0.4796541143103011}, 'imdb:': {10: 0.6041156544821036, 25: 0.792314629642197, 50: 0.8841244907992167, 75: 0.919645972585134, 100: 0.9384990165105116}, 'mmlu': {10: 0.5081387925039232, 25: 0.7208835989785465, 50: 0.83780634484103, 75: 0.8856908221000853, 100: 0.9117460576767137}, 'msmarco:track=regular,valid_topk=30,': {10: 0.6953250955734614, 25: 0.8508679651505742, 50: 0.919425892253047, 75: 0.9448014022477752, 100: 0.9580217667834137}, 'narrative_qa:': {10: 0.7684867094282389, 25: 0.8924559588644965, 50: 0.9431722357227104, 75: 0.9613833240287174, 100: 0.9707551583783545}, 'natural_qa:mode=closedbook,': {10: 0.22977593855447995, 25: 0.42719957235446904, 50: 0.5986542886216152, 75: 0.6911126553957527, 100: 0.7489477779936828}, 'natural_qa:mode=openbook_longans,': {10: 0.09609038014892819, 25: 0.20996283711852115, 50: 0.34705667096113363, 75: 0.44360667800025283, 100: 0.5152814702495129}, 'quac:': {10: 0.16252089470914344, 25: 0.32666693335237773, 50: 0.49246261460201984, 75: 0.5927422281685694, 100: 0.6599329320330612}, 'raft': {10: 0.16811577037202072, 25: 0.33564787444977023, 50: 0.5025993465351678, 75: 0.6024927808332723, 100: 0.6689731999339781}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.7897296258539234, 25: 0.9037485537757671, 50: 0.949441092925148, 75: 0.9657162794699456, 100: 0.9740649218597376}}}\n",
      "\n",
      "iii) running anchor points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [31:33<00:00, 378.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iv) running random eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [19:00<00:00, 228.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v) running anchor points with IRT embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [28:47<00:00, 345.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models [4, 12, 13]\n",
      "\n",
      "i) choosing optimal D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [05:34<00:00, 111.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- opt D= 10 errors= [0.04014776870666264, 0.03758734187511835, 0.03701439713524953] \n",
      "\n",
      "\n",
      "ii) choosing optimal lambdas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15/15 [00:00<00:00, 12818.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_gpirt': {'cnn': {10: 0.2715794190775654, 25: 0.4824239312122899, 50: 0.6508582613311908, 75: 0.7365821147348108, 100: 0.788508955101164}, 'xsum': {10: 0.2833470942934764, 25: 0.49709296492559607, 50: 0.6640776178522768, 75: 0.747813367075591, 100: 0.7981329845771992}, 'boolq:': {10: 0.14899051660003776, 25: 0.30443859597020734, 50: 0.4667733642820862, 75: 0.5676727798031007, 100: 0.6364628314757391}, 'civil_comments': {10: 0.008348902948679956, 25: 0.020614099695106605, 50: 0.04039548287891528, 75: 0.05939360758913104, 100: 0.07765409124448619}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.0270920533280044, 25: 0.06508519592184368, 50: 0.12221594323355832, 75: 0.1727665042144695, 100: 0.2178118105886194}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.017040616643927916, 25: 0.04153974724732871, 50: 0.07976603361919415, 75: 0.11506010627606876, 100: 0.14774688429831753}, 'imdb:': {10: 0.3651840890700465, 25: 0.5898528881878127, 50: 0.7420219726872391, 75: 0.8118337271674472, 100: 0.8519088557104681}, 'mmlu': {10: 0.06611302107827498, 25: 0.15037039141039188, 50: 0.2614295231052198, 75: 0.3468109712473971, 100: 0.4144972324124257}, 'msmarco:track=regular,valid_topk=30,': {10: 0.2534491516819246, 25: 0.45908921939995734, 50: 0.6292819017451933, 75: 0.7180081009885311, 100: 0.7724653432547709}, 'narrative_qa:': {10: 0.16177420570111498, 25: 0.32545916692631144, 50: 0.4910889373997672, 75: 0.5914147785253776, 100: 0.6586983848946686}, 'natural_qa:mode=closedbook,': {10: 0.06906518165298449, 25: 0.15645460550770746, 50: 0.27057630236860125, 75: 0.3574990658798962, 100: 0.42591114262747454}, 'natural_qa:mode=openbook_longans,': {10: 0.060444491707523314, 25: 0.13854940658288598, 50: 0.2433788218268236, 75: 0.3254628502224638, 100: 0.3914797607204558}, 'quac:': {10: 0.011027838138910109, 25: 0.027120966897599085, 50: 0.05280968410082697, 75: 0.07717668789733721, 100: 0.10032142541684566}, 'raft': {10: 0.09728933010387522, 25: 0.21224898317692106, 50: 0.3501739100175339, 75: 0.4469974437103525, 100: 0.5187093416921179}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.16781648332727797, 25: 0.33517050509746804, 50: 0.5020639743281334, 75: 0.6019797808682531, 100: 0.6684987895441729}}, 'anchor_gpirt': {'cnn': {10: 0.5986084615677818, 25: 0.788508955101164, 50: 0.8817500777417839, 75: 0.917931868435392, 100: 0.9371596028309331}, 'xsum': {10: 0.6126286951874241, 25: 0.7981329845771992, 50: 0.8877352136053127, 75: 0.9222471742798568, 100: 0.9405293784925074}, 'boolq:': {10: 0.41186854467351347, 25: 0.6364628314757391, 50: 0.7778518634630839, 75: 0.8400576074924535, 100: 0.8750468803940769}, 'civil_comments': {10: 0.032579600038241556, 25: 0.07765409124448619, 50: 0.14411691446336075, 75: 0.20164513440177442, 100: 0.2519269012484754}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.10022251236318744, 25: 0.2178118105886194, 50: 0.3577101300788696, 75: 0.45515789941518836, 100: 0.5269315182292853}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.0648473500766208, 25: 0.14774688429831753, 50: 0.257455517971009, 75: 0.3421403202696222, 100: 0.409486481695084}, 'imdb:': {10: 0.6970651026637958, 25: 0.8519088557104681, 50: 0.9200332436270369, 75: 0.9452288726181524, 100: 0.9583513688430196}, 'mmlu': {10: 0.22068218622468308, 25: 0.4144972324124257, 50: 0.5860700507776894, 75: 0.6798772337216212, 100: 0.7390216472347166}, 'msmarco:track=regular,valid_topk=30,': {10: 0.5759071050557669, 25: 0.7724653432547709, 50: 0.8716281491138167, 75: 0.9105929847318157, 100: 0.931411669060991}, 'narrative_qa:': {10: 0.43566078867527036, 25: 0.6586983848946686, 50: 0.794235276157814, 75: 0.8527219768514835, 100: 0.8853189843180367}, 'natural_qa:mode=closedbook,': {10: 0.22884505146291878, 25: 0.42591114262747454, 50: 0.5973880558120384, 75: 0.6899870673640328, 100: 0.7479560819782815}, 'natural_qa:mode=openbook_longans,': {10: 0.20466529724386878, 25: 0.3914797607204558, 50: 0.562681214303487, 75: 0.6587021567445547, 100: 0.7201484335425168}, 'quac:': {10: 0.04269872855394979, 25: 0.10032142541684566, 50: 0.18234930830114462, 75: 0.25066927774696374, 100: 0.30845251402591467}, 'raft': {10: 0.30123613506487457, 25: 0.5187093416921179, 50: 0.6830923172095346, 75: 0.7637742982171741, 100: 0.8117110514081134}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.44648387301430237, 25: 0.6684987895441729, 50: 0.8013176799808217, 75: 0.8581508113563624, 100: 0.8897016765963827}}, 'anchor-irt_gpirt': {'cnn': {10: 0.5986084615677818, 25: 0.788508955101164, 50: 0.8817500777417839, 75: 0.917931868435392, 100: 0.9371596028309331}, 'xsum': {10: 0.6126286951874241, 25: 0.7981329845771992, 50: 0.8877352136053127, 75: 0.9222471742798568, 100: 0.9405293784925074}, 'boolq:': {10: 0.41186854467351347, 25: 0.6364628314757391, 50: 0.7778518634630839, 75: 0.8400576074924535, 100: 0.8750468803940769}, 'civil_comments': {10: 0.032579600038241556, 25: 0.07765409124448619, 50: 0.14411691446336075, 75: 0.20164513440177442, 100: 0.2519269012484754}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.10022251236318744, 25: 0.2178118105886194, 50: 0.3577101300788696, 75: 0.45515789941518836, 100: 0.5269315182292853}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.0648473500766208, 25: 0.14774688429831753, 50: 0.257455517971009, 75: 0.3421403202696222, 100: 0.409486481695084}, 'imdb:': {10: 0.6970651026637958, 25: 0.8519088557104681, 50: 0.9200332436270369, 75: 0.9452288726181524, 100: 0.9583513688430196}, 'mmlu': {10: 0.22068218622468308, 25: 0.4144972324124257, 50: 0.5860700507776894, 75: 0.6798772337216212, 100: 0.7390216472347166}, 'msmarco:track=regular,valid_topk=30,': {10: 0.5759071050557669, 25: 0.7724653432547709, 50: 0.8716281491138167, 75: 0.9105929847318157, 100: 0.931411669060991}, 'narrative_qa:': {10: 0.43566078867527036, 25: 0.6586983848946686, 50: 0.794235276157814, 75: 0.8527219768514835, 100: 0.8853189843180367}, 'natural_qa:mode=closedbook,': {10: 0.22884505146291878, 25: 0.42591114262747454, 50: 0.5973880558120384, 75: 0.6899870673640328, 100: 0.7479560819782815}, 'natural_qa:mode=openbook_longans,': {10: 0.20466529724386878, 25: 0.3914797607204558, 50: 0.562681214303487, 75: 0.6587021567445547, 100: 0.7201484335425168}, 'quac:': {10: 0.04269872855394979, 25: 0.10032142541684566, 50: 0.18234930830114462, 75: 0.25066927774696374, 100: 0.30845251402591467}, 'raft': {10: 0.30123613506487457, 25: 0.5187093416921179, 50: 0.6830923172095346, 75: 0.7637742982171741, 100: 0.8117110514081134}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.44648387301430237, 25: 0.6684987895441729, 50: 0.8013176799808217, 75: 0.8581508113563624, 100: 0.8897016765963827}}}\n",
      "\n",
      "iii) running anchor points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [18:18<00:00, 219.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iv) running random eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [07:39<00:00, 91.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v) running anchor points with IRT embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [17:22<00:00, 208.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models [14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "\n",
      "i) choosing optimal D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [05:47<00:00, 115.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- opt D= 5 errors= [0.045810498090451464, 0.04502040451789275, 0.046899226917154604] \n",
      "\n",
      "\n",
      "ii) choosing optimal lambdas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 15/15 [00:00<00:00, 87624.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_gpirt': {'cnn': {10: 0.7893264856506694, 25: 0.9035373144834618, 50: 0.9493245103300146, 75: 0.9656358671333084, 100: 0.9740035641056983}, 'xsum': {10: 0.7145113195727499, 25: 0.8622003906464604, 50: 0.9260017288978751, 75: 0.9494202136852479, 100: 0.9615793329819754}, 'boolq:': {10: 0.10702135504182779, 25: 0.23054373347519364, 50: 0.3747022185454754, 75: 0.4733674171260726, 100: 0.5451394687380875}, 'civil_comments': {10: 0.0040268472962810995, 25: 0.010006675211174428, 50: 0.0198150674778109, 75: 0.029431012467722242, 100: 0.03886011907397521}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.041670195611746445, 25: 0.09804703061222278, 50: 0.17858439188630393, 75: 0.24591802716214067, 100: 0.30304896809380394}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.01387779422219853, 25: 0.03398698889825317, 50: 0.06573968388996347, 75: 0.09547139613376172, 100: 0.12336912077818626}, 'imdb:': {10: 0.27637074250160265, 25: 0.4884407550444779, 50: 0.6563119874124681, 75: 0.7412291822525554, 100: 0.792498022595097}, 'mmlu': {10: 0.14323615706977139, 25: 0.2947599655823727, 50: 0.45531214034686657, 75: 0.5563188478543634, 100: 0.6257243758556774}, 'msmarco:track=regular,valid_topk=30,': {10: 0.3998493279986525, 25: 0.6248528385863984, 50: 0.7691192996037877, 75: 0.8332461151606958, 100: 0.86949399034428}, 'narrative_qa:': {10: 0.14102545156698287, 25: 0.2910049683192669, 50: 0.4508192849143258, 75: 0.5518390780861903, 100: 0.6214685586302332}, 'natural_qa:mode=closedbook,': {10: 0.20177508566790428, 25: 0.3872358837451993, 50: 0.5582841220914163, 75: 0.6546780132087302, 100: 0.716537009107335}, 'natural_qa:mode=openbook_longans,': {10: 0.1513663992161852, 25: 0.30839503016263553, 50: 0.47140966306529236, 75: 0.5722357609631611, 100: 0.6407592323177153}, 'quac:': {10: 0.026832843891859474, 25: 0.06448657252896259, 50: 0.12115995484237643, 75: 0.17135900746067947, 100: 0.21613321867067628}, 'raft': {10: 0.04673041237541599, 25: 0.1091734504019451, 50: 0.1968555059848981, 75: 0.26882356001376184, 100: 0.3289545062048318}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.11721363097831639, 25: 0.24921668808035724, 50: 0.3989967320454593, 75: 0.49895449216214094, 100: 0.5704040944571617}}, 'anchor_gpirt': {'cnn': {10: 0.9374480999536772, 25: 0.9740035641056983, 50: 0.986830603365157, 75: 0.9911816916433055, 100: 0.9933716560372395}, 'xsum': {10: 0.9091822502392638, 25: 0.9615793329819754, 50: 0.9804134013995662, 75: 0.9868564551540158, 100: 0.99010984343643}, 'boolq:': {10: 0.32404591985222814, 25: 0.5451394687380875, 50: 0.7056184632747773, 75: 0.7823924247109738, 100: 0.8274048135243494}, 'civil_comments': {10: 0.015915125840739137, 25: 0.03886011907397521, 50: 0.0748129962070631, 75: 0.10817311682136323, 100: 0.13921118645024338}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.14815930125233265, 25: 0.30304896809380394, 50: 0.46513826496808686, 75: 0.5660594436970964, 100: 0.6349411193328137}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.05329243264716109, 25: 0.12336912077818626, 50: 0.21964128886278333, 75: 0.29686051971305, 100: 0.36017358688730683}, 'imdb:': {10: 0.6043822535233174, 25: 0.792498022595097, 50: 0.8842386575665556, 75: 0.9197283192014959, 100: 0.9385633332759731}, 'mmlu': {10: 0.4007422770562884, 25: 0.6257243758556774, 50: 0.7697791644740962, 75: 0.8337623168815943, 100: 0.8699155012403393}, 'msmarco:track=regular,valid_topk=30,': {10: 0.7271481793677248, 25: 0.86949399034428, 50: 0.9301918003856828, 75: 0.9523524708484074, 100: 0.9638335425524196}, 'narrative_qa:': {10: 0.3963960221842589, 25: 0.6214685586302332, 50: 0.766550242769099, 75: 0.8312340375230373, 100: 0.8678499192499817}, 'natural_qa:mode=closedbook,': {10: 0.5027643707406956, 25: 0.716537009107335, 50: 0.8348634550908537, 75: 0.88349594431958, 100: 0.9100006354963511}, 'natural_qa:mode=openbook_longans,': {10: 0.4163853455416575, 25: 0.6407592323177153, 50: 0.7810521125791101, 75: 0.8425431250061398, 100: 0.8770682306966103}, 'quac:': {10: 0.09933504990607829, 25: 0.21613321867067628, 50: 0.3554433270179494, 75: 0.45270882505326454, 100: 0.5244680023619201}, 'raft': {10: 0.16393885816276188, 25: 0.3289545062048318, 50: 0.4950575880046416, 75: 0.5952458857679729, 100: 0.6622588881881982}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.3468780253423645, 25: 0.5704040944571617, 50: 0.7264424442988122, 75: 0.7993300344386757, 100: 0.8415484068961869}}, 'anchor-irt_gpirt': {'cnn': {10: 0.9374480999536772, 25: 0.9740035641056983, 50: 0.986830603365157, 75: 0.9911816916433055, 100: 0.9933716560372395}, 'xsum': {10: 0.9091822502392638, 25: 0.9615793329819754, 50: 0.9804134013995662, 75: 0.9868564551540158, 100: 0.99010984343643}, 'boolq:': {10: 0.32404591985222814, 25: 0.5451394687380875, 50: 0.7056184632747773, 75: 0.7823924247109738, 100: 0.8274048135243494}, 'civil_comments': {10: 0.015915125840739137, 25: 0.03886011907397521, 50: 0.0748129962070631, 75: 0.10817311682136323, 100: 0.13921118645024338}, 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,': {10: 0.14815930125233265, 25: 0.30304896809380394, 50: 0.46513826496808686, 75: 0.5660594436970964, 100: 0.6349411193328137}, 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,': {10: 0.05329243264716109, 25: 0.12336912077818626, 50: 0.21964128886278333, 75: 0.29686051971305, 100: 0.36017358688730683}, 'imdb:': {10: 0.6043822535233174, 25: 0.792498022595097, 50: 0.8842386575665556, 75: 0.9197283192014959, 100: 0.9385633332759731}, 'mmlu': {10: 0.4007422770562884, 25: 0.6257243758556774, 50: 0.7697791644740962, 75: 0.8337623168815943, 100: 0.8699155012403393}, 'msmarco:track=regular,valid_topk=30,': {10: 0.7271481793677248, 25: 0.86949399034428, 50: 0.9301918003856828, 75: 0.9523524708484074, 100: 0.9638335425524196}, 'narrative_qa:': {10: 0.3963960221842589, 25: 0.6214685586302332, 50: 0.766550242769099, 75: 0.8312340375230373, 100: 0.8678499192499817}, 'natural_qa:mode=closedbook,': {10: 0.5027643707406956, 25: 0.716537009107335, 50: 0.8348634550908537, 75: 0.88349594431958, 100: 0.9100006354963511}, 'natural_qa:mode=openbook_longans,': {10: 0.4163853455416575, 25: 0.6407592323177153, 50: 0.7810521125791101, 75: 0.8425431250061398, 100: 0.8770682306966103}, 'quac:': {10: 0.09933504990607829, 25: 0.21613321867067628, 50: 0.3554433270179494, 75: 0.45270882505326454, 100: 0.5244680023619201}, 'raft': {10: 0.16393885816276188, 25: 0.3289545062048318, 50: 0.4950575880046416, 75: 0.5952458857679729, 100: 0.6622588881881982}, 'truthful_qa:task=mc_single,method=multiple_choice_joint,': {10: 0.3468780253423645, 25: 0.5704040944571617, 50: 0.7264424442988122, 75: 0.7993300344386757, 100: 0.8415484068961869}}}\n",
      "\n",
      "iii) running anchor points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [36:42<00:00, 440.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iv) running random eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [24:04<00:00, 288.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v) running anchor points with IRT embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 1/5 [06:36<26:27, 396.81s/it]"
     ]
    }
   ],
   "source": [
    "scenario_name = 'full' #we are evaluating all scenarios at once\n",
    "chosen_scenarios = list(scenarios.keys())\n",
    "sampling = {'random_sampling':True,'anchor_sampling':True,\n",
    "            'anchor-irt_sampling':True,'disc_sampling':False}\n",
    "results_full, accs_full = evaluate_scenarios(data, scenario_name, chosen_scenarios, scenarios, set_of_rows, Ds, iterations, device, bench='irt_helm', sampling = sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/results_full_helm.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_full, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('results/accs_full_helm.pickle', 'wb') as handle:\n",
    "    pickle.dump(accs_full, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/results_full_helm.pickle', 'rb') as handle:\n",
    "    results_full = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['anchor-irt_naive', 'anchor-irt_cirt', 'anchor-irt_pirt', 'anchor-irt_gpirt']\n",
    "plot_results(results_full, scenarios.keys(), methods = methods)\n",
    "plot_agg_results(results_full, scenarios.keys(), methods = methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e568dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['anchor_naive', 'anchor_cirt', 'anchor_pirt', 'anchor_gpirt']\n",
    "plot_results(results_full, scenarios.keys(), methods = methods)\n",
    "plot_agg_results(results_full, scenarios.keys(), methods = methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f46a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['random_naive', 'random_cirt', 'random_pirt', 'random_gpirt']\n",
    "plot_results(results_full, scenarios.keys(), methods = methods)\n",
    "plot_agg_results(results_full, scenarios.keys(), methods = methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db483f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3b3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b380b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('results/results_full_helm.pickle', 'rb') as handle:\n",
    "    results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sce in scenarios.keys():\n",
    "    y=np.stack([results[m][100]['random_gpirt'][sce] for m in results.keys()]).mean(axis=1)\n",
    "    x=np.vstack([data['data'][s]['correctness'] for s in scenarios[sce]]).mean(axis=0)\n",
    "    plt.plot(x,y,'bo')\n",
    "    plt.xlabel('acc')\n",
    "    plt.ylabel('error')\n",
    "    plt.title(sce)\n",
    "    plt.savefig(f'plots/scenario-{sce}.png', bbox_inches='tight', dpi=300, transparent=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b0b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e345c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
