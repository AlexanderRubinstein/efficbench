{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a612e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def load_core_scenarios(\n",
    "     agg_res_paths=[\"data/agg_data_v0.2.2_v3\"],\n",
    "     scenarios_to_take=[],\n",
    "     blacklist=[],\n",
    "     lite=False,\n",
    " ):\n",
    "    \"\"\"Load the core scenarios from the aggregated results.\"\"\"\n",
    "    #agg_data_paths = [\n",
    "    #     os.path.join(os.getcwd(), agg_res_path) for agg_res_path in agg_res_paths\n",
    "    #]\n",
    "    paths = []\n",
    "    for agg_res_path in agg_res_paths:\n",
    "        paths.extend(\n",
    "             [\n",
    "                 f\"{agg_res_path}/{subscenario_agg_filename}\"\n",
    "                 for subscenario_agg_filename in os.listdir(agg_res_path)\n",
    "                 if subscenario_agg_filename.endswith(\".csv\")\n",
    "             ]\n",
    "         )\n",
    "    if lite:\n",
    "        import random\n",
    "        print(\"sampling a subset of subscenarios\")\n",
    "        paths = random.sample(paths, k=3)\n",
    "    if scenarios_to_take:\n",
    "        paths = [\n",
    "             path\n",
    "             for path in paths\n",
    "             if any([scenario in path for scenario in scenarios_to_take])\n",
    "         ]\n",
    "        print(f\"only a part of scenarios taken: {scenarios_to_take}\")\n",
    "    if blacklist:\n",
    "        paths = [\n",
    "             path\n",
    "             for path in paths\n",
    "             if not any([scenario in path for scenario in blacklist])\n",
    "         ]\n",
    "    df = []\n",
    "    for path in tqdm(paths, desc=\"Getting core scenarions\"):\n",
    "        df.append(pd.read_csv(path))\n",
    "    df = pd.concat(df)\n",
    "\n",
    "    def extract_scenario_name(x):\n",
    "        x = x.split(\"v0.0.2/\")[-1].split(\"v0.2.2/\")[-1].split(\"v0.2.3/\")[-1]\n",
    "        if \"msmarco\" in x:\n",
    "            x = x.split(\",\")[0]\n",
    "        elif \"natural_qa\" in x:\n",
    "            x = x.split(\",model\")[0].replace(\"_longans\", \"\")\n",
    "        elif \"hellaswag\" in x:\n",
    "            x = \"hellaswag\"\n",
    "        elif \"openbookqa\" in x:\n",
    "            x = \"openbookqa\"\n",
    "        else:\n",
    "            x = x.split(\":\")[0]\n",
    "        return x\n",
    "    \n",
    "    #df=df.fillna(\"NaN\")\n",
    "    #print(df.columns)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df[\"scenario\"] = [extract_scenario_name(x) for x in df[\"data_augmentations\"]]\n",
    "    df[\"subscenario\"] = df[\"data_augmentations\"].apply(\n",
    "        lambda x: x.split(\"model\")[0].split(\"/\")[-1]\n",
    "     )\n",
    "    #return df[['model','unique_id_inc_seed','score','scenario', \"subscenario\"]]\n",
    "\n",
    "    balanced_df = []\n",
    "    for scenario, group_df in df.groupby(\"scenario\", group_keys=False):\n",
    "        group_df[\"balanced_score\"] = get_balanced_score_col(group_df)\n",
    "        balanced_df.append(group_df)\n",
    "    return pd.concat(balanced_df)[['model','unique_id_inc_seed','balanced_score','scenario', \"subscenario\",\"instance_id\",\"score_name\"]]\n",
    "\n",
    "    \n",
    "def get_balanced_score_col(df, column_to_balance=\"sub_split\"):\n",
    "    # need to balance civil_comments\n",
    "    balance = False  # default is nothing to balance\n",
    "    if column_to_balance in df.columns:  # is there a subsplit\n",
    "        if len(df[column_to_balance].unique()) > 1:  # are there two splits\n",
    "            balance = True\n",
    "            assert (\n",
    "                 df.scenario.unique()[0] == \"civil_comments\"\n",
    "            ), f\"we are balancing more than civil comments? df.scenario.unique()[0]={df.scenario.unique()[0]}\"\n",
    "    if balance:\n",
    "         df[\"weight\"] = df.groupby(column_to_balance)[\"unique_id_inc_seed\"].transform(\n",
    "             lambda x: 1 - len(x) / len(df)\n",
    "         )\n",
    "         balanced_score = df[\"score\"].mul(df[\"weight\"]).values.tolist()\n",
    "    else:\n",
    "         balanced_score = df[\"score\"].values.tolist()\n",
    "    return balanced_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f18c2",
   "metadata": {},
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b90609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting core scenarions: 100%|██████████████████| 38/38 [00:08<00:00,  4.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(742594, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_core_scenarios()\n",
    "df = df.drop_duplicates(subset=['model','subscenario','instance_id'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b588459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for sub in list(df.subscenario.unique()):\n",
    "    models.append(list(df.loc[df.subscenario==sub].model.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e93c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists = models\n",
    "\n",
    "intersection = set(list_of_lists[0])\n",
    "\n",
    "for sublist in list_of_lists[1:]:\n",
    "    intersection = intersection.intersection(set(sublist))\n",
    "\n",
    "intersection = list(np.sort(list(intersection)))\n",
    "\n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25318a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boolq: (1000, 28) 1.0\n",
      "civil_comments:demographic=LGBTQ, (1000, 28) 1.0\n",
      "civil_comments:demographic=all, (1000, 28) 1.0\n",
      "civil_comments:demographic=black, (1000, 28) 1.0\n",
      "civil_comments:demographic=christian, (1000, 28) 1.0\n",
      "civil_comments:demographic=female, (1000, 28) 1.0\n",
      "civil_comments:demographic=male, (1000, 28) 1.0\n",
      "civil_comments:demographic=muslim, (1000, 28) 1.0\n",
      "civil_comments:demographic=other_religions, (1000, 28) 1.0\n",
      "civil_comments:demographic=white, (1000, 28) 1.0\n",
      "commonsense:dataset=hellaswag,method=multiple_choice_separate_original, (1000, 28) 1.0\n",
      "commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated, (500, 28) 1.0\n",
      "imdb: (989, 28) 0.9782393669634025\n",
      "mmlu:subject=abstract_algebra,method=multiple_choice_joint, (111, 28) 1.0\n",
      "mmlu:subject=college_chemistry,method=multiple_choice_joint, (108, 28) 1.0\n",
      "mmlu:subject=computer_security,method=multiple_choice_joint, (111, 28) 1.0\n",
      "mmlu:subject=econometrics,method=multiple_choice_joint, (126, 28) 1.0\n",
      "mmlu:subject=us_foreign_policy,method=multiple_choice_joint, (111, 28) 1.0\n",
      "msmarco:track=regular,valid_topk=30, (1000, 28) 1.0\n",
      "msmarco:track=trec,valid_topk=30, (43, 28) 1.0\n",
      "narrative_qa: (470, 28) 1.0\n",
      "natural_qa:mode=closedbook, (1000, 28) 1.0\n",
      "natural_qa:mode=openbook_longans, (1000, 28) 1.0\n",
      "quac: (1000, 28) 1.0\n",
      "raft:subset=ade_corpus_v2, (40, 28) 1.0\n",
      "raft:subset=banking_77, (40, 28) 1.0\n",
      "raft:subset=neurips_impact_statement_risks, (40, 28) 1.0\n",
      "raft:subset=one_stop_english, (40, 28) 1.0\n",
      "raft:subset=overruling, (40, 28) 1.0\n",
      "raft:subset=semiconductor_org_types, (40, 28) 1.0\n",
      "raft:subset=systematic_review_inclusion, (40, 28) 1.0\n",
      "raft:subset=tai_safety_research, (40, 28) 1.0\n",
      "raft:subset=terms_of_service, (40, 28) 1.0\n",
      "raft:subset=tweet_eval_hate, (40, 28) 1.0\n",
      "raft:subset=twitter_complaints, (40, 28) 1.0\n",
      "summarization_cnndm:temperature=0.3,device=cuda, (1000, 28) 1.0\n",
      "summarization_xsum:temperature=0.3,device=cuda, (1000, 28) 1.0\n",
      "truthful_qa:task=mc_single,method=multiple_choice_joint, (654, 28) 1.0\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data['models'] = intersection\n",
    "data['data'] = {}\n",
    "\n",
    "for sub in list(np.sort(df.subscenario.unique())):\n",
    "    data['data'][sub] = {}\n",
    "    data['data'][sub]['score_name'] = df.loc[df.subscenario==sub]['score_name'].unique()[0]\n",
    "    data_aux = df.loc[df.subscenario==sub]\n",
    "    data_aux = data_aux.loc[[mod in intersection for mod in data_aux.model]]\n",
    "    data['data'][sub]['correctness'] = np.array(data_aux.pivot_table(index='model', columns='instance_id', values='balanced_score')).T\n",
    "    k1 = data['data'][sub]['correctness'].shape[0]\n",
    "    arr = data['data'][sub]['correctness']\n",
    "    data['data'][sub]['correctness'] = arr[np.sum(np.isnan(arr), axis=1)==0]\n",
    "    k2 = data['data'][sub]['correctness'].shape[0]\n",
    "    \n",
    "    print(sub, data['data'][sub]['correctness'].shape, k2/k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a30d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/helm.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804f49f",
   "metadata": {},
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee48bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting core scenarions: 100%|██████████████████| 38/38 [00:03<00:00,  9.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(742594, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_core_scenarios()\n",
    "df = df.drop_duplicates(subset=['model','subscenario','instance_id'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60acac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boolq: 36 (1000, 36) 1.0\n",
      "civil_comments:demographic=LGBTQ, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=all, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=black, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=christian, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=female, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=male, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=muslim, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=other_religions, 37 (1000, 37) 1.0\n",
      "civil_comments:demographic=white, 37 (1000, 37) 1.0\n",
      "commonsense:dataset=hellaswag,method=multiple_choice_separate_original, 29 (1000, 29) 1.0\n",
      "commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated, 29 (500, 29) 1.0\n",
      "imdb: 37 (989, 37) 0.9782393669634025\n",
      "mmlu:subject=abstract_algebra,method=multiple_choice_joint, 37 (111, 37) 1.0\n",
      "mmlu:subject=college_chemistry,method=multiple_choice_joint, 37 (108, 37) 1.0\n",
      "mmlu:subject=computer_security,method=multiple_choice_joint, 37 (111, 37) 1.0\n",
      "mmlu:subject=econometrics,method=multiple_choice_joint, 37 (126, 37) 1.0\n",
      "mmlu:subject=us_foreign_policy,method=multiple_choice_joint, 37 (111, 37) 1.0\n",
      "msmarco:track=regular,valid_topk=30, 28 (1000, 28) 1.0\n",
      "msmarco:track=trec,valid_topk=30, 29 (43, 29) 1.0\n",
      "narrative_qa: 37 (470, 37) 1.0\n",
      "natural_qa:mode=closedbook, 37 (1000, 37) 1.0\n",
      "natural_qa:mode=openbook_longans, 37 (1000, 37) 1.0\n",
      "quac: 37 (1000, 37) 1.0\n",
      "raft:subset=ade_corpus_v2, 37 (40, 37) 1.0\n",
      "raft:subset=banking_77, 37 (40, 37) 1.0\n",
      "raft:subset=neurips_impact_statement_risks, 37 (40, 37) 1.0\n",
      "raft:subset=one_stop_english, 37 (40, 37) 1.0\n",
      "raft:subset=overruling, 37 (40, 37) 1.0\n",
      "raft:subset=semiconductor_org_types, 37 (40, 37) 1.0\n",
      "raft:subset=systematic_review_inclusion, 37 (40, 37) 1.0\n",
      "raft:subset=tai_safety_research, 37 (40, 37) 1.0\n",
      "raft:subset=terms_of_service, 37 (40, 37) 1.0\n",
      "raft:subset=tweet_eval_hate, 37 (40, 37) 1.0\n",
      "raft:subset=twitter_complaints, 37 (40, 37) 1.0\n",
      "summarization_cnndm:temperature=0.3,device=cuda, 37 (1000, 37) 1.0\n",
      "summarization_xsum:temperature=0.3,device=cuda, 37 (1000, 37) 1.0\n",
      "truthful_qa:task=mc_single,method=multiple_choice_joint, 37 (654, 37) 1.0\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data['data'] = {}\n",
    "\n",
    "for sub in list(np.sort(df.subscenario.unique())):\n",
    "    data['data'][sub] = {}\n",
    "    data['data'][sub]['models'] = list(np.sort(list(df.loc[df.subscenario==sub].model.unique())))\n",
    "    data['data'][sub]['score_name'] = df.loc[df.subscenario==sub]['score_name'].unique()[0]\n",
    "    data['data'][sub]['correctness'] = np.array(df.loc[df.subscenario==sub].pivot_table(index='model', columns='instance_id', values='balanced_score')).T\n",
    "    k1 = data['data'][sub]['correctness'].shape[0]\n",
    "    arr = data['data'][sub]['correctness']\n",
    "    data['data'][sub]['correctness'] = arr[np.sum(np.isnan(arr), axis=1)==0]\n",
    "    k2 = data['data'][sub]['correctness'].shape[0]\n",
    "    \n",
    "    print(sub, len(data['data'][sub]['models']), data['data'][sub]['correctness'].shape, k2/k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299befc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/helm_all_models.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
