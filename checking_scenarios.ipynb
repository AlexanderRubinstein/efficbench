{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56afb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from irt import *\n",
    "from selection import *\n",
    "from utils import *\n",
    "from acc import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef1962e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cnn', 'xsum', 'boolq:', 'civil_comments', 'commonsense:dataset=hellaswag,method=multiple_choice_separate_original,', 'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,', 'imdb:', 'mmlu', 'msmarco:track=regular,valid_topk=30,', 'narrative_qa:', 'natural_qa:mode=closedbook,', 'natural_qa:mode=openbook_longans,', 'quac:', 'raft', 'truthful_qa:task=mc_single,method=multiple_choice_joint,'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/helm_all_models.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "scenarios = helm_scenarios\n",
    "scenarios.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn nope (eg first model returns 0.164 instead of 0.161)\n",
    "#xsum nope (eg first model returns 0.169 instead of 0.17)\n",
    "#'narrative_qa:' (eg first model returns 0.752 instead of 0.755)\n",
    "\n",
    "#'boolq:' ok\n",
    "#hellaswag ok\n",
    "#'commonsense:dataset=openbookqa,method=multiple_choice_separate_calibrated,' ok\n",
    "#marco ok\n",
    "#natural_qa:mode=closedbook,', ok\n",
    "#'natural_qa:mode=openbook_longans,' ok\n",
    "#'quac:' ok\n",
    "#raft ok\n",
    "#'truthful_qa:task=mc_single,method=multiple_choice_joint,' ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "49e91820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truthful_qa:task=mc_single,method=multiple_choice_joint,']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario='truthful_qa:task=mc_single,method=multiple_choice_joint,'\n",
    "scenarios[scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5016d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data([scenario], scenarios, data)\n",
    "scores = create_responses([scenario], scenarios, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc727a7",
   "metadata": {},
   "source": [
    "overall score (simple avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc95ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 654)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:,scenarios_position[scenario]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e52df12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60958206, 0.59327217, 0.37691131, 0.36811927, 0.3058104 ,\n",
       "       0.26911315, 0.25739042, 0.25076453, 0.25038226, 0.23292559,\n",
       "       0.23190622, 0.23190622, 0.22222222, 0.22069317, 0.21827217,\n",
       "       0.2166157 , 0.21597859, 0.21508665, 0.21508665, 0.20489297,\n",
       "       0.20336391, 0.20183486, 0.20107034, 0.19915902, 0.19775739,\n",
       "       0.19673802, 0.19367992, 0.19317023, 0.19304281, 0.19011213,\n",
       "       0.18756371, 0.18246687, 0.1814475 , 0.17482161, 0.16921509,\n",
       "       0.16666667, 0.13302752])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = scores[:,scenarios_position[scenario]].mean(axis=1)\n",
    "ind = np.argsort(-sc)\n",
    "sc[ind] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f53416d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai_text-davinci-002',\n",
       " 'openai_text-davinci-003',\n",
       " 'together_t0pp',\n",
       " 'anthropic_stanford-online-all-v4-s3',\n",
       " 'ai21_j1-grande-v2-beta',\n",
       " 'cohere_command-xlarge-beta',\n",
       " 'openai_text-curie-001',\n",
       " 'microsoft_TNLGv2_530B',\n",
       " 'together_opt-175b',\n",
       " 'openai_text-babbage-001',\n",
       " 'openai_text-ada-001',\n",
       " 'openai_curie',\n",
       " 'AlephAlpha_luminous-supreme',\n",
       " 'AlephAlpha_luminous-extended',\n",
       " 'together_glm',\n",
       " 'cohere_small-20220720',\n",
       " 'together_gpt-neox-20b',\n",
       " 'openai_ada',\n",
       " 'cohere_medium-20221108',\n",
       " 'together_bloom',\n",
       " 'cohere_command-medium-beta',\n",
       " 'together_yalm',\n",
       " 'together_opt-66b',\n",
       " 'together_gpt-j-6b',\n",
       " 'cohere_xlarge-20220609',\n",
       " 'ai21_j1-large',\n",
       " 'openai_davinci',\n",
       " 'ai21_j1-grande',\n",
       " 'together_ul2',\n",
       " 'cohere_medium-20220720',\n",
       " 'openai_babbage',\n",
       " 'AlephAlpha_luminous-base',\n",
       " 'cohere_large-20220720',\n",
       " 'ai21_j1-jumbo',\n",
       " 'cohere_xlarge-20221108',\n",
       " 'microsoft_TNLGv2_7B',\n",
       " 'together_t5-11b']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data['data'][scenario]['models'][i] for i in ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c8e6c",
   "metadata": {},
   "source": [
    "overall score (equal weights for subscenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8afe4ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16970594, 0.1560045 , 0.15310345, 0.15272467, 0.14938479,\n",
       "       0.13734121, 0.13493151, 0.13435057, 0.13382303, 0.13358483,\n",
       "       0.13124521, 0.12776435, 0.12429681, 0.12285571, 0.12199009,\n",
       "       0.12141414, 0.11802182, 0.11241361, 0.10901321, 0.10895923,\n",
       "       0.10470761, 0.10420329, 0.09995084, 0.0975719 , 0.08951568,\n",
       "       0.08945656, 0.08526363, 0.07451999, 0.05403337, 0.04766607,\n",
       "       0.04522996, 0.0337985 , 0.03300947, 0.03250128, 0.02174086,\n",
       "       0.02036477, 0.01511773])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = np.vstack([data['data'][sub]['correctness'].mean(axis=0) for sub in scenarios[scenario]]).mean(axis=0)\n",
    "ind = np.argsort(-sc)\n",
    "sc[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb08dd9",
   "metadata": {},
   "source": [
    "subscenario score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f993c381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mmlu:subject=abstract_algebra,method=multiple_choice_joint,', 'mmlu:subject=college_chemistry,method=multiple_choice_joint,', 'mmlu:subject=computer_security,method=multiple_choice_joint,', 'mmlu:subject=econometrics,method=multiple_choice_joint,', 'mmlu:subject=us_foreign_policy,method=multiple_choice_joint,'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscenarios_position[scenario].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aecce68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33933934, 0.3003003 , 0.2972973 , 0.28828829, 0.28228228,\n",
       "       0.27327327, 0.27027027, 0.27027027, 0.27027027, 0.26726727,\n",
       "       0.26726727, 0.26426426, 0.26426426, 0.26426426, 0.26426426,\n",
       "       0.26126126, 0.26126126, 0.25825826, 0.25825826, 0.25825826,\n",
       "       0.25825826, 0.25225225, 0.25225225, 0.24924925, 0.24924925,\n",
       "       0.24924925, 0.24924925, 0.24024024, 0.23723724, 0.23123123,\n",
       "       0.22222222, 0.21921922, 0.21921922, 0.21921922, 0.21621622,\n",
       "       0.2012012 , 0.16216216])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = 'mmlu:subject=abstract_algebra,method=multiple_choice_joint,'\n",
    "ind = np.argsort(-scores[:,subscenarios_position[scenario][sub]].mean(axis=1))\n",
    "scores[:,subscenarios_position[scenario][sub]].mean(axis=1)[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bdf11",
   "metadata": {},
   "source": [
    "only for civil_comments: giving equal importance to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bda41f",
   "metadata": {},
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc40b444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68015474, 0.66381119, 0.60036158, 0.5970088 , 0.59416885,\n",
       "       0.58856111, 0.56438046, 0.54054913, 0.53777574, 0.53645595,\n",
       "       0.53306377, 0.53284046, 0.53101177, 0.52820255, 0.52578662,\n",
       "       0.52492297, 0.52481494, 0.52233583, 0.51922222, 0.51827271,\n",
       "       0.51362572, 0.51352538, 0.51119076, 0.51078797, 0.50482545,\n",
       "       0.50361981, 0.50357628, 0.50234344, 0.50084985, 0.50055177,\n",
       "       0.50049299, 0.49916587, 0.49859525, 0.49309423, 0.49123352,\n",
       "       0.48632782, 0.23231353])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic = np.hstack([data['data'][sub]['weight'].mean(axis=1)>1 for sub in scenarios[scenario]])\n",
    "sc = (scores[:,scenarios_position[scenario]][:,toxic].mean(axis=1)+scores[:,scenarios_position[scenario]][:,~toxic].mean(axis=1))/2\n",
    "ind = np.argsort(-sc)\n",
    "sc[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11776984",
   "metadata": {},
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e852097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65391219, 0.64221811, 0.60831122, 0.59408889, 0.59406103,\n",
       "       0.57447049, 0.57380883, 0.5579776 , 0.55605006, 0.5425277 ,\n",
       "       0.54056186, 0.53663365, 0.53397306, 0.53392779, 0.53325916,\n",
       "       0.5324077 , 0.53154579, 0.53093114, 0.52515375, 0.52313741,\n",
       "       0.52027309, 0.51782145, 0.51752718, 0.51369474, 0.51343878,\n",
       "       0.50994588, 0.50979614, 0.50959416, 0.50890637, 0.50177257,\n",
       "       0.5       , 0.5       , 0.5       , 0.49814211, 0.49682749,\n",
       "       0.48731169, 0.31154537])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = 'civil_comments:demographic=LGBTQ,'\n",
    "toxic = data['data'][sub]['weight'].mean(axis=1)>1\n",
    "sc = (scores[:,subscenarios_position[scenario][sub]][:,toxic].mean(axis=1)+scores[:,subscenarios_position[scenario][sub]][:,~toxic].mean(axis=1))/2\n",
    "ind = np.argsort(-sc)\n",
    "sc[ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
